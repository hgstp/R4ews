[
["index.html", "R4ews MA009 Willkommen zur R Ergänzung zur Einführung in die Wahrscheinlichkeitstheorie und Statistik Beteiligte Personen Kolophon Lizenz", " R4ews MA009 Stephan Haug Willkommen zur R Ergänzung zur Einführung in die Wahrscheinlichkeitstheorie und Statistik Im Rahmen dieser Ergänzung lernen wir Daten untersuchen, aufbereiten, visualisieren und analysieren, Wir wollen all das reproduzierbar, wiederverwendbar und gemeinsam nutzbar machen, und vor allem wollen wir alles mit R machen. Auf dieser Website geht es um alles, was bei der Datenanalyse auftaucht außer um statistische Modellierung und Schlussfolgerungen. Dieser Teil der statistischen Analyse erfolgt in der Vorlesung Einführung in die Wahrscheinlichkeitstheorie und Statistik. Das Design von R4ews wurde durch die Notwendigkeit motiviert, mehr Ausgewogenheit in der angewandten statistischen Ausbildung zu schaffen. Datenanalysten verbringen viel Zeit mit der Projektorganisation, der Datenbereinigung und -aufbereitung sowie der Kommunikation. Diese Tätigkeiten können einen tiefgreifenden Einfluss auf die Qualität und Glaubwürdigkeit einer Analyse haben. Dennoch werden diese Fähigkeiten selten vermittelt, obwohl sie so wichtig und notwendig sind. R4ews zielt darauf ab, diese Lücke zu schließen. Beteiligte Personen Kolophon Dieses Buch wurde in bookdown innerhalb von RStudio geschrieben. Teile des Buches basieren auf stat545.com. Alle Änderungen wurden gemäß der Creative Commons Attribution-ShareAlike 4.0 International License durchgeführt. Wir bedanken uns bei den Autor*innen von stat545 für das großartige Material. Die aktuelle Version dieses Buchs wurde mit #&gt; Finding R package dependencies ... Done! #&gt; setting value #&gt; version R version 4.0.2 (2020-06-22) #&gt; os macOS Catalina 10.15.7 #&gt; system x86_64, darwin17.0 #&gt; ui X11 #&gt; language (EN) #&gt; collate en_US.UTF-8 #&gt; ctype en_US.UTF-8 #&gt; tz Europe/Berlin #&gt; date 2020-10-29 erstellt, wobei die folgenden Pakete verwendet werden. Lizenz Diese Arbeit ist lizensiert unter Creative Commons Attribution-ShareAlike 4.0 International License. "],
["install.html", "Kapitel 1 Installieren von R und RStudio 1.1 R und RStudio 1.2 Funktioniert? Ausprobieren 1.3 Add-on packages 1.4 RStudio Primers 1.5 Aufgabe", " Kapitel 1 Installieren von R und RStudio 1.1 R und RStudio Installieren Sie R, eine freie Softwareumgebung für statistische Berechnungen und Grafiken von CRAN, dem Comprehensive R Archive Network. Wir empfehle Ihnen dringend, eine vorkompilierte Binärdistribution für Ihr Betriebssystem zu installieren - benutzen Sie die Links oben auf der CRAN Seite! Installieren Sie die IDE von RStudio (steht für integrated development environment), eine leistungsfähige Benutzeroberfläche für R. Holen Sie sich die Open-Source-Edition von RStudio Desktop. Es ist vorteilhaft die Preview version zu installieren. In der Regel ist sie bereits sehr stabil und man hat so Zugriff auf die neusten Features. Natürlich gibt es auch offizielle Veröffentlichungen here. RStudio wird mit einem Text Editor geliefert, so dass es nicht unmittelbar erforderlich ist, einen separaten, eigenständigen Editor zu installieren. RStudio kann eine Schnittstelle zu Git(Hub) bilden. Sie müssen jedoch alle Git(Hub)-Installationen selbst vornehmen. Wir kommen später auf diesen Punkt zurück. Wenn Sie eine bereits vorhandene R und/oder RStudio Installation haben, empfehlen wir Ihnen dringend, beide neu zu installieren und so aktuell wie möglich zu halten. Wenn Sie R aktualisieren, müssen Sie alle Pakete, die Sie installiert haben, aktualisieren. Der unten stehende Befehl sollte Ihnen den Anfang machen, obwohl Sie möglicherweise weitere Argumente angeben müssen, wenn Sie z.B. eine nicht standardmäßige Bibliothek für Ihre Pakete verwendet haben. update.packages(ask = FALSE, checkBuilt = TRUE) Bemerkung: hier wird nur nach Updates auf CRAN gesucht. Wenn Sie also ein Paket verwenden, das z.B. nur auf GitHub lebt, müssen Sie manuell aktualisieren, z.B. über devtools::install_github(). 1.2 Funktioniert? Ausprobieren Starten Sie RStudio auf Ihrem Computer. Sie sollten ein Fenster ähnlich zu diesem Screenshot, erhalten. Setzen Sie den Cursor in den Bereich mit der Bezeichnung Konsole, wo Sie mit R interagieren können. Erstellen Sie ein einfaches Objekt mit einem Code wie x &lt;- 2 * 4 (gefolgt von Enter oder Return). Inspizieren Sie dann das x-Objekt durch Eingabe von x gefolgt von Enter oder Return. Sie sollten den Wert 8 auf dem Bildschirm sehen. Wenn ja, haben Sie R und RStudio erfolgreich installiert. 1.3 Add-on packages R ist ein erweiterbares System und viele Menschen teilen nützlichen Code, den sie als Paket entwickelt haben, über CRAN und GitHub. Um ein Paket von CRAN zu installieren, z.B. das Paket tidyverse (ist genauer gesagt eine Kollektion von Paketen), kann man folgenden Befehl verwenden install.packages(&quot;tidyverse&quot;, dependencies = TRUE) Mit der Option dependencies = TRUE achten wir darauf, dass alle für tidyverse notwendigen Pakete, ebenfalls installiert werden. 1.4 RStudio Primers Ein guter Startpunkt für verschiedene R Themen sind die RStudio primers. Im Laufe des Kurses werden sie die Primers The Basics Work with Data Visualize Data durcharbeiten. 1.5 Aufgabe Wir beginnen mit The Basics. Hier wird unterschieden in Programming and Visualization Basics. Programming Basics beinhaltet Grundlagen zu Objekttypen, Funktionen und deren Argumente, Listen (eigentlich sind alle Objekte Listen, nur unterschiedlich speziell) und Paketen. Visualization Basics erklärt erste Schritte in der Verwendung des ggplot2 Pakets, mit dem wir uns später noch eingehend beschäftigen werden. Bearbeiten sie eigenständig den Basics Primer. "],
["r-basics.html", "Kapitel 2 R Basics und Arbeitsabläufe 2.1 Ein paar Grundlagen für das Arbeiten mit R 2.2 Workspace and working directory 2.3 RStudio projects 2.4 Stuff", " Kapitel 2 R Basics und Arbeitsabläufe 2.1 Ein paar Grundlagen für das Arbeiten mit R Sie haben bereits den Programming Basics Primer besucht. Nun wollen sie selbst mit ihrer RStudio/R Installation arbeiten. Es geht los indem sie RStudio starten. Beachten Sie die Standardfensterbereiche: Console (links) Environment / History (oben rechts) Files / Plots / Packages / Help (unten rechtes) Bemerkung: Die Standardanordnung der Fenster können sie neben vielen anderen Dingen aber auch ändern/anpassen: Customizing RStudio. Gehen sie in die Konsole, wo wir mit dem R interagieren können. Nehmen Sie eine Zuordnung vor und inspizieren Sie dann das gerade erstellte Objekt: x &lt;- 3 * 4 x #&gt; [1] 12 Alle R Befehle, in denen Sie Objekte erstellen (“Zuweisungen”), haben diese Form: objectName &lt;- value Sie werden viele Zuweisungen vornehmen, und es ist mühsam, den Operator &lt;- zu tippen. Seien sie aber trotzdem nicht faul und benutzen = stattdessen, obwohl es theoretisch funktionieren würde. Aber später kann das für Verwirrung sorgen. Verwenden Sie stattdessen in RStudio die Tastenkombination: Alt + - (Minuszeichen). Beachten Sie, dass RStudio automatisch &lt;- mit Leerzeichen umgibt, was eine nützliche Codeformatierung demonstriert. Code ist selbst an einem guten Tag eher schlecht zu lesen. Gönnen Sie Ihren Augen eine Pause und verwenden Sie Leerzeichen. RStudio bietet viele praktische Tastaturkürzel an. Eine Übersicht erhält man auch mit Alt+Shift+K. Objektnamen dürfen nicht mit einer Ziffer beginnen und bestimmte andere Zeichen wie ein Komma oder ein Leerzeichen nicht enthalten. Es ist daher ratsam, sich eine Konvention zur Abgrenzung von Wörtern in Objektnamen zu überlegen. i_use_snake_case other.people.use.periods evenOthersUseCamelCase Wir werden stets die erste Variante verwenden. Führen sie nachfolgenden Befehl aus this_is_a_really_long_name &lt;- 2.5 Ihr Workspace enthält nun das Objekt this_is_a_really_long_name. Probieren sie mithilfe dieses Objekts die Vervollständigungsfunktion von RStudio aus: Geben sie die ersten paar Zeichen ein, drücken sie dann die TAB Taste, fügen Sie Zeichen hinzu, bis sie die Eindeutigkeit herstellen (wenn sonst wenig in ihrem Workspace ist, dann ist das schnell erreicht), und drücken sie dann die Eingabetaste. Führen sie nun den Befehl jenny_rocks &lt;- 2 ^ 3 aus, um anschließend den Inhalt des Objekts anzuzeigen. jennyrocks #&gt; Error in eval(expr, envir, enclos): object &#39;jennyrocks&#39; not found jeny_rocks #&gt; Error in eval(expr, envir, enclos): object &#39;jeny_rocks&#39; not found Das Objekt jennyrocks ist natürlich nicht vorhanden und führt somit auch zu einer Fehlermeldung. Man muss also absolut exakt sein mit seinen Befehlen. R hat eine überwältigende Sammlung eingebauter Funktionen, auf die auf diese Weise zugegriffen wird: functionName(arg1 = val1, arg2 = val2, and so on) Als nächstes wollen wir die Funktion seq() verwenden, die reguläre Zahlensequenzen erzeugt. Dabei wollen wir noch ein weiteres hilfreiches Feature von RStudio demonstrieren. Tippen sie se und drücken sie dann die TAB Taste. In einem Pop-Up Fenster sehen sie mögliche Vervollständigungen. Specify seq() by typing more to disambiguate or using the up/down arrows to select. Notice the floating tool-tip-type help that pops up, reminding you of a function’s arguments. If you want even more help, press F1 as directed to get the full documentation in the help tab of the lower right pane. Now open the parentheses and notice the automatic addition of the closing parenthesis and the placement of cursor in the middle. Type the arguments 1, 10 and hit return. RStudio also exits the parenthetical expression for you. IDEs are great. seq(1, 10) #&gt; [1] 1 2 3 4 5 6 7 8 9 10 The above also demonstrates something about how R resolves function arguments. You can always specify in name = value form. But if you do not, R attempts to resolve by position. So above, it is assumed that we want a sequence from = 1 that goes to = 10. Since we didn’t specify step size, the default value of by in the function definition is used, which ends up being 1 in this case. For functions I call often, I might use this resolve by position for the first argument or maybe the first two. After that, I always use name = value. Make this assignment and notice similar help with quotation marks. yo &lt;- &quot;hello world&quot; If you just make an assignment, you don’t get to see the value, so then you’re tempted to immediately inspect. y &lt;- seq(1, 10) y #&gt; [1] 1 2 3 4 5 6 7 8 9 10 This common action can be shortened by surrounding the assignment with parentheses, which causes assignment and “print to screen” to happen. (y &lt;- seq(1, 10)) #&gt; [1] 1 2 3 4 5 6 7 8 9 10 Not all functions have (or require) arguments: date() #&gt; [1] &quot;Thu Oct 29 14:06:52 2020&quot; Now look at your workspace – in the upper right pane. The workspace is where user-defined objects accumulate. You can also get a listing of these objects with commands: objects() #&gt; [1] &quot;check_quietly&quot; &quot;install_quietly&quot; #&gt; [3] &quot;jenny_rocks&quot; &quot;pretty_install&quot; #&gt; [5] &quot;shhh_check&quot; &quot;this_is_a_really_long_name&quot; #&gt; [7] &quot;x&quot; &quot;y&quot; #&gt; [9] &quot;yo&quot; ls() #&gt; [1] &quot;check_quietly&quot; &quot;install_quietly&quot; #&gt; [3] &quot;jenny_rocks&quot; &quot;pretty_install&quot; #&gt; [5] &quot;shhh_check&quot; &quot;this_is_a_really_long_name&quot; #&gt; [7] &quot;x&quot; &quot;y&quot; #&gt; [9] &quot;yo&quot; If you want to remove the object named y, you can do this: rm(y) To remove everything: rm(list = ls()) or click the broom in RStudio’s Environment pane. 2.2 Workspace and working directory One day you will need to quit R, go do something else and return to your analysis later. One day you will have multiple analyses going that use R and you want to keep them separate. One day you will need to bring data from the outside world into R and send numerical results and figures from R back out into the world. To handle these real life situations, you need to make two decisions: What about your analysis is “real”, i.e. will you save it as your lasting record of what happened? Where does your analysis “live”? 2.2.1 Workspace, .RData As a beginning R user, it’s OK to consider your workspace “real”. Very soon, I urge you to evolve to the next level, where you consider your saved R scripts as “real”. (In either case, of course the input data is very much real and requires preservation!) With the input data and the R code you used, you can reproduce everything. You can make your analysis fancier. You can get to the bottom of puzzling results and discover and fix bugs in your code. You can reuse the code to conduct similar analyses in new projects. You can remake a figure with different aspect ratio or save is as TIFF instead of PDF. You are ready to take questions. You are ready for the future. If you regard your workspace as “real” (saving and reloading all the time), if you need to redo analysis … you’re going to either redo a lot of typing (making mistakes all the way) or will have to mine your R history for the commands you used. Rather than becoming an expert on managing the R history, a better use of your time and psychic energy is to keep your “good” R code in a script for future reuse. Because it can be useful sometimes, note the commands you’ve recently run appear in the History pane. But you don’t have to choose right now and the two strategies are not incompatible. Let’s demo the save / reload the workspace approach. Upon quitting R, you have to decide if you want to save your workspace, for potential restoration the next time you launch R. Depending on your set up, R or your IDE, e.g. RStudio, will probably prompt you to make this decision. Quit R/RStudio, either from the menu, using a keyboard shortcut, or by typing q() in the Console. You’ll get a prompt like this: Save workspace image to ~/.Rdata? Note where the workspace image is to be saved and then click “Save”. Using your favorite method, visit the directory where image was saved and verify there is a file named .RData. You will also see a file .Rhistory, holding the commands submitted in your recent session. Restart RStudio. In the Console you will see a line like this: [Workspace loaded from ~/.RData] indicating that your workspace has been restored. Look in the Workspace pane and you’ll see the same objects as before. In the History tab of the same pane, you should also see your command history. You’re back in business. This way of starting and stopping analytical work will not serve you well for long but it’s a start. 2.2.2 Working directory Any process running on your computer has a notion of its “working directory”. In R, this is where R will look, by default, for files you ask it to load. It also where, by default, any files you write to disk will go. Chances are your current working directory is the directory we inspected above, i.e. the one where RStudio wanted to save the workspace. You can explicitly check your working directory with: getwd() It is also displayed at the top of the RStudio console. As a beginning R user, it’s OK let your home directory or any other weird directory on your computer be R’s working directory. Very soon, I urge you to evolve to the next level, where you organize your analytical projects into directories and, when working on project A, set R’s working directory to the associated directory. Although I do not recommend it, in case you’re curious, you can set R’s working directory at the command line like so: setwd(&quot;~/myCoolProject&quot;) Although I do not recommend it, you can also use RStudio’s Files pane to navigate to a directory and then set it as working directory from the menu: Session &gt; Set Working Directory &gt; To Files Pane Location. (You’ll see even more options there). Or within the Files pane, choose “More” and “Set As Working Directory”. But there’s a better way. A way that also puts you on the path to managing your R work like an expert. 2.3 RStudio projects Keeping all the files associated with a project organized together – input data, R scripts, analytical results, figures – is such a wise and common practice that RStudio has built-in support for this via its projects. Let’s make one to use for the rest of this workshop/class. Do this: File &gt; New Project…. The directory name you choose here will be the project name. Call it whatever you want (or follow me for convenience). I created a directory and, therefore RStudio project, called swc in my tmp directory, FYI. setwd(&quot;~/tmp/swc&quot;) Now check that the “home” directory for your project is the working directory of our current R process: getwd() I can’t print my output here because this document itself does not reside in the RStudio Project we just created. Let’s enter a few commands in the Console, as if we are just beginning a project: a &lt;- 2 b &lt;- -3 sig_sq &lt;- 0.5 x &lt;- runif(40) y &lt;- a + b * x + rnorm(40, sd = sqrt(sig_sq)) (avg_x &lt;- mean(x)) #&gt; [1] 0.497 write(avg_x, &quot;avg_x.txt&quot;) plot(x, y) abline(a, b, col = &quot;purple&quot;) dev.print(pdf, &quot;toy_line_plot.pdf&quot;) #&gt; quartz_off_screen #&gt; 2 Let’s say this is a good start of an analysis and your ready to start preserving the logic and code. Visit the History tab of the upper right pane. Select these commands. Click “To Source”. Now you have a new pane containing a nascent R script. Click on the floppy disk to save. Give it a name ending in .R or .r, I used toy-line.r and note that, by default, it will go in the directory associated with your project. Quit RStudio. Inspect the folder associated with your project if you wish. Maybe view the PDF in an external viewer. Restart RStudio. Notice that things, by default, restore to where we were earlier, e.g. objects in the workspace, the command history, which files are open for editing, where we are in the file system browser, the working directory for the R process, etc. These are all Good Things. Change some things about your code. Top priority would be to set a sample size n at the top, e.g. n &lt;- 40, and then replace all the hard-wired 40’s with n. Change some other minor-but-detectable stuff, e.g. alter the sample size n, the slope of the line b,the color of the line … whatever. Practice the different ways to re-run the code: Walk through line by line by keyboard shortcut (Command+Enter) or mouse (click “Run” in the upper right corner of editor pane). Source the entire document – equivalent to entering source('toy-line.r') in the Console – by keyboard shortcut (Shift+Command+S) or mouse (click “Source” in the upper right corner of editor pane or select from the mini-menu accessible from the associated down triangle). Source with echo from the Source mini-menu. Visit your figure in an external viewer to verify that the PDF is changing as you expect. In your favorite OS-specific way, search your files for toy_line_plot.pdf and presumably you will find the PDF itself (no surprise) but also the script that created it (toy-line.r). This latter phenomenon is a huge win. One day you will want to remake a figure or just simply understand where it came from. If you rigorously save figures to file with R code and not ever ever ever the mouse or the clipboard, you will sing my praises one day. Trust me. 2.4 Stuff It is traditional to save R scripts with a .R or .r suffix. Follow this convention unless you have some extraordinary reason not to. Comments start with one or more # symbols. Use them. RStudio helps you (de)comment selected lines with Ctrl+Shift+C (Windows and Linux) or Command+Shift+C (Mac). Clean out the workspace, i.e. pretend like you’ve just revisited this project after a long absence. The broom icon or rm(list = ls()). Good idea to do this, restart R (available from the Session menu), re-run your analysis to truly check that the code you’re saving is complete and correct (or at least rule out obvious problems!). This workflow will serve you well in the future: Create an RStudio project for an analytical project Keep inputs there (we’ll soon talk about importing) Keep scripts there; edit them, run them in bits or as a whole from there Keep outputs there (like the PDF written above) Avoid using the mouse for pieces of your analytical workflow, such as loading a dataset or saving a figure. Terribly important for reproducibility and for making it possible to retrospectively determine how a numerical table or PDF was actually produced (searching on local disk on filename, among .R files, will lead to the relevant script). Many long-time users never save the workspace, never save .RData files (I’m one of them), never save or consult the history. Once/if you get to that point, there are options available in RStudio to disable the loading of .RData and permanently suppress the prompt on exit to save the workspace (go to Tools &gt; Options &gt; General). For the record, when loading data into R and/or writing outputs to file, you can always specify the absolute path and thereby insulate yourself from the current working directory. This is rarely necessary when using RStudio projects properly. "],
["overview.html", "Overview", " Overview Although this part now links out to external resources, if you’re working through this material on your own, let this be a nudge to pause around here and think about your workflow. I give you permission to spend some time and energy sorting this out! It can be as or more important than learning a new R function or package. The experts don’t talk about this much, because they’ve already got a workflow and it’s something they do almost without thinking. Working through subsequent material in R Markdown documents, possibly using Git and GitHub to track and share your progress, is a great idea and will leave you more prepared for your future data analysis projects. Typing individual lines of R code is but a small part of data analysis and it pays off to think holistically about your workflow. "],
["version-control.html", "Kapitel 3 Git, GitHub, and RStudio", " Kapitel 3 Git, GitHub, and RStudio At this point in STAT 545, all students receive their own STAT 545 GitHub repository that they will use to develop their course work throughout the rest of the course. This has two purposes: It is helpful for course mechanics, e.g. homework submission and grading, peer review. Learning to use Git and GitHub, with R and RStudio, is a legitimate pedagogical goal. Our instructions around installation, setup, and early Git usage eventually grew so extensive that we created a dedicated website. This content can now be found here: https://happygitwithr.com "],
["r-markdown.html", "Kapitel 4 R Markdown", " Kapitel 4 R Markdown STAT 545 course work is generally submitted in the form of R Markdown documents. Students submit an .Rmd file, which they have executed or rendered to a .md markdown file. R Markdown is a very accessible way to create computational documents that combine prose and tables and figures produced by R code. An introductory R Markdown workflow, including how it intersects with Git, GitHub, and RStudio, is now maintained within the Happy Git site: Test drive R Markdown "],
["basic-data-care.html", "Kapitel 5 Basic care and feeding of data in R 5.1 Buckle your seatbelt 5.2 Data frames are awesome 5.3 Get the Gapminder data 5.4 Meet the gapminder data frame or “tibble” 5.5 Look at the variables inside a data frame 5.6 Recap", " Kapitel 5 Basic care and feeding of data in R 5.1 Buckle your seatbelt Ignore if you don’t need this bit of support. Now is the time to make sure you are working in an appropriate directory on your computer, probably through the use of an RStudio project. Enter getwd() in the Console to see current working directory or, in RStudio, this is displayed in the bar at the top of Console. You should clean out your workspace. In RStudio, click on the “Clear” broom icon from the Environment tab or use Session &gt; Clear Workspace. You can also enter rm(list = ls()) in the Console to accomplish same. Now restart R. This will ensure you don’t have any packages loaded from previous calls to library(). In RStudio, use Session &gt; Restart R. Otherwise, quit R with q() and re-launch it. Why do we do this? So that the code you write is complete and re-runnable. If you return to a clean slate often, you will root out hidden dependencies where one snippet of code only works because it relies on objects created by code saved elsewhere or, much worse, never saved at all. Similarly, an aggressive clean slate approach will expose any usage of packages that have not been explicitly loaded. Finally, open a new R script and develop and run your code from there. In RStudio, use File &gt; New File &gt; R Script. Save this script with a name ending in .r or .R, containing no spaces or other funny stuff, and that evokes whatever it is we’re doing today. Example: cm004_data-care-feeding.r. Another great idea is to do this in an R Markdown document. See Test drive R Markdown for a refresher. 5.2 Data frames are awesome Whenever you have rectangular, spreadsheet-y data, your default data receptacle in R is a data frame. Do not depart from this without good reason. Data frames are awesome because… Data frames package related variables neatly together, keeping them in sync vis-a-vis row order applying any filtering of observations uniformly Most functions for inference, modelling, and graphing are happy to be passed a data frame via a data = argument. This has been true in base R for a long time. The set of packages known as the tidyverse takes this one step further and explicitly prioritizes the processing of data frames. This includes popular packages like dplyr and ggplot2. In fact the tidyverse prioritizes a special flavor of data frame, called a “tibble”. Data frames – unlike general arrays or, specifically, matrices in R – can hold variables of different flavors, such as character data (subject ID or name), quantitative data (white blood cell count), and categorical information (treated vs. untreated). If you use homogeneous structures, like matrices, for data analysis, you are likely to make the terrible mistake of spreading a dataset out over multiple, unlinked objects. Why? Because you can’t put character data, such as subject name, into the numeric matrix that holds white blood cell count. This fragmentation is a Bad Idea. 5.3 Get the Gapminder data We will work with some of the data from the Gapminder project. I’ve released this as an R package called gapminder, so we can install it from CRAN like so: install.packages(&quot;gapminder&quot;) Now load the package: library(gapminder) 5.4 Meet the gapminder data frame or “tibble” By loading the gapminder package, we now have access to a data frame by the same name. Get an overview of this with str(), which displays the structure of an object. str(gapminder) #&gt; tibble [1,704 × 6] (S3: tbl_df/tbl/data.frame) #&gt; $ country : Factor w/ 142 levels &quot;Afghanistan&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... #&gt; $ continent: Factor w/ 5 levels &quot;Africa&quot;,&quot;Americas&quot;,..: 3 3 3 3 3 3 3 3 3 3 ... #&gt; $ year : int [1:1704] 1952 1957 1962 1967 1972 1977 1982 1987 1992 1997 ... #&gt; $ lifeExp : num [1:1704] 28.8 30.3 32 34 36.1 ... #&gt; $ pop : int [1:1704] 8425333 9240934 10267083 11537966 13079460 14880372.. #&gt; $ gdpPercap: num [1:1704] 779 821 853 836 740 ... str() will provide a sensible description of almost anything and, worst case, nothing bad can actually happen. When in doubt, just str() some of the recently created objects to get some ideas about what to do next. We could print the gapminder object itself to screen. However, if you’ve used R before, you might be reluctant to do this, because large datasets just fill up your Console and provide very little insight. This is the first big win for tibbles. The tidyverse offers a special case of R’s default data frame: the “tibble”, which is a nod to the actual class of these objects, tbl_df. If you have not already done so, install the tidyverse meta-package now: install.packages(&quot;tidyverse&quot;) Now load it: library(tidyverse) #&gt; ── Attaching packages ──────────────────────────── tidyverse 1.3.0 ── #&gt; ✓ ggplot2 3.3.2 ✓ purrr 0.3.4 #&gt; ✓ tibble 3.0.3 ✓ dplyr 1.0.2 #&gt; ✓ tidyr 1.1.2 ✓ stringr 1.4.0 #&gt; ✓ readr 1.3.1 ✓ forcats 0.5.0 #&gt; ── Conflicts ─────────────────────────────── tidyverse_conflicts() ── #&gt; x dplyr::filter() masks stats::filter() #&gt; x dplyr::lag() masks stats::lag() Now we can boldly print gapminder to screen! It is a tibble (and also a regular data frame) and the tidyverse provides a nice print method that shows the most important stuff and doesn’t fill up your Console. ## see? it&#39;s still a regular data frame, but also a tibble class(gapminder) #&gt; [1] &quot;tbl_df&quot; &quot;tbl&quot; &quot;data.frame&quot; gapminder #&gt; # A tibble: 1,704 x 6 #&gt; country continent year lifeExp pop gdpPercap #&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 Afghanistan Asia 1952 28.8 8425333 779. #&gt; 2 Afghanistan Asia 1957 30.3 9240934 821. #&gt; 3 Afghanistan Asia 1962 32.0 10267083 853. #&gt; 4 Afghanistan Asia 1967 34.0 11537966 836. #&gt; 5 Afghanistan Asia 1972 36.1 13079460 740. #&gt; 6 Afghanistan Asia 1977 38.4 14880372 786. #&gt; 7 Afghanistan Asia 1982 39.9 12881816 978. #&gt; 8 Afghanistan Asia 1987 40.8 13867957 852. #&gt; 9 Afghanistan Asia 1992 41.7 16317921 649. #&gt; 10 Afghanistan Asia 1997 41.8 22227415 635. #&gt; # … with 1,694 more rows If you are dealing with plain vanilla data frames, you can rein in data frame printing explicitly with head() and tail(). Or turn it into a tibble with as_tibble()! head(gapminder) #&gt; # A tibble: 6 x 6 #&gt; country continent year lifeExp pop gdpPercap #&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 Afghanistan Asia 1952 28.8 8425333 779. #&gt; 2 Afghanistan Asia 1957 30.3 9240934 821. #&gt; 3 Afghanistan Asia 1962 32.0 10267083 853. #&gt; 4 Afghanistan Asia 1967 34.0 11537966 836. #&gt; 5 Afghanistan Asia 1972 36.1 13079460 740. #&gt; 6 Afghanistan Asia 1977 38.4 14880372 786. tail(gapminder) #&gt; # A tibble: 6 x 6 #&gt; country continent year lifeExp pop gdpPercap #&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 Zimbabwe Africa 1982 60.4 7636524 789. #&gt; 2 Zimbabwe Africa 1987 62.4 9216418 706. #&gt; 3 Zimbabwe Africa 1992 60.4 10704340 693. #&gt; 4 Zimbabwe Africa 1997 46.8 11404948 792. #&gt; 5 Zimbabwe Africa 2002 40.0 11926563 672. #&gt; 6 Zimbabwe Africa 2007 43.5 12311143 470. as_tibble(iris) #&gt; # A tibble: 150 x 5 #&gt; Sepal.Length Sepal.Width Petal.Length Petal.Width Species #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; #&gt; 1 5.1 3.5 1.4 0.2 setosa #&gt; 2 4.9 3 1.4 0.2 setosa #&gt; 3 4.7 3.2 1.3 0.2 setosa #&gt; 4 4.6 3.1 1.5 0.2 setosa #&gt; 5 5 3.6 1.4 0.2 setosa #&gt; 6 5.4 3.9 1.7 0.4 setosa #&gt; 7 4.6 3.4 1.4 0.3 setosa #&gt; 8 5 3.4 1.5 0.2 setosa #&gt; 9 4.4 2.9 1.4 0.2 setosa #&gt; 10 4.9 3.1 1.5 0.1 setosa #&gt; # … with 140 more rows More ways to query basic info on a data frame: names(gapminder) #&gt; [1] &quot;country&quot; &quot;continent&quot; &quot;year&quot; &quot;lifeExp&quot; &quot;pop&quot; &quot;gdpPercap&quot; ncol(gapminder) #&gt; [1] 6 length(gapminder) #&gt; [1] 6 dim(gapminder) #&gt; [1] 1704 6 nrow(gapminder) #&gt; [1] 1704 A statistical overview can be obtained with summary(): summary(gapminder) #&gt; country continent year lifeExp #&gt; Afghanistan: 12 Africa :624 Min. :1952 Min. :23.6 #&gt; Albania : 12 Americas:300 1st Qu.:1966 1st Qu.:48.2 #&gt; Algeria : 12 Asia :396 Median :1980 Median :60.7 #&gt; Angola : 12 Europe :360 Mean :1980 Mean :59.5 #&gt; Argentina : 12 Oceania : 24 3rd Qu.:1993 3rd Qu.:70.8 #&gt; Australia : 12 Max. :2007 Max. :82.6 #&gt; (Other) :1632 #&gt; pop gdpPercap #&gt; Min. :6.00e+04 Min. : 241 #&gt; 1st Qu.:2.79e+06 1st Qu.: 1202 #&gt; Median :7.02e+06 Median : 3532 #&gt; Mean :2.96e+07 Mean : 7215 #&gt; 3rd Qu.:1.96e+07 3rd Qu.: 9325 #&gt; Max. :1.32e+09 Max. :113523 #&gt; Although we haven’t begun our formal coverage of visualization yet, it’s so important for smell-testing dataset that we will make a few figures anyway. Here we use only base R graphics, which are very basic. plot(lifeExp ~ year, gapminder) plot(lifeExp ~ gdpPercap, gapminder) plot(lifeExp ~ log(gdpPercap), gapminder) Let’s go back to the result of str() to talk about what a data frame is. str(gapminder) #&gt; tibble [1,704 × 6] (S3: tbl_df/tbl/data.frame) #&gt; $ country : Factor w/ 142 levels &quot;Afghanistan&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... #&gt; $ continent: Factor w/ 5 levels &quot;Africa&quot;,&quot;Americas&quot;,..: 3 3 3 3 3 3 3 3 3 3 ... #&gt; $ year : int [1:1704] 1952 1957 1962 1967 1972 1977 1982 1987 1992 1997 ... #&gt; $ lifeExp : num [1:1704] 28.8 30.3 32 34 36.1 ... #&gt; $ pop : int [1:1704] 8425333 9240934 10267083 11537966 13079460 14880372.. #&gt; $ gdpPercap: num [1:1704] 779 821 853 836 740 ... A data frame is a special case of a list, which is used in R to hold just about anything. Data frames are a special case where the length of each list component is the same. Data frames are superior to matrices in R because they can hold vectors of different flavors, e.g. numeric, character, and categorical data can be stored together. This comes up a lot! 5.5 Look at the variables inside a data frame To specify a single variable from a data frame, use the dollar sign $. Let’s explore the numeric variable for life expectancy. head(gapminder$lifeExp) #&gt; [1] 28.8 30.3 32.0 34.0 36.1 38.4 summary(gapminder$lifeExp) #&gt; Min. 1st Qu. Median Mean 3rd Qu. Max. #&gt; 23.6 48.2 60.7 59.5 70.8 82.6 hist(gapminder$lifeExp) The year variable is an integer variable, but since there are so few unique values it also functions a bit like a categorical variable. summary(gapminder$year) #&gt; Min. 1st Qu. Median Mean 3rd Qu. Max. #&gt; 1952 1966 1980 1980 1993 2007 table(gapminder$year) #&gt; #&gt; 1952 1957 1962 1967 1972 1977 1982 1987 1992 1997 2002 2007 #&gt; 142 142 142 142 142 142 142 142 142 142 142 142 The variables for country and continent hold truly categorical information, which is stored as a factor in R. class(gapminder$continent) #&gt; [1] &quot;factor&quot; summary(gapminder$continent) #&gt; Africa Americas Asia Europe Oceania #&gt; 624 300 396 360 24 levels(gapminder$continent) #&gt; [1] &quot;Africa&quot; &quot;Americas&quot; &quot;Asia&quot; &quot;Europe&quot; &quot;Oceania&quot; nlevels(gapminder$continent) #&gt; [1] 5 The levels of the factor continent are “Africa”, “Americas”, etc. and this is what’s usually presented to your eyeballs by R. In general, the levels are friendly human-readable character strings, like “male/female” and “control/treated”. But never ever ever forget that, under the hood, R is really storing integer codes 1, 2, 3, etc. Look at the result from str(gapminder$continent) if you are skeptical. str(gapminder$continent) #&gt; Factor w/ 5 levels &quot;Africa&quot;,&quot;Americas&quot;,..: 3 3 3 3 3 3 3 3 3 3 ... This Janus-like nature of factors means they are rich with booby traps for the unsuspecting but they are a necessary evil. I recommend you resolve to learn how to properly care and feed for factors. The pros far outweigh the cons. Specifically in modelling and figure-making, factors are anticipated and accommodated by the functions and packages you will want to exploit. Here we count how many observations are associated with each continent and, as usual, try to portray that info visually. This makes it much easier to quickly see that African countries are well represented in this dataset. table(gapminder$continent) #&gt; #&gt; Africa Americas Asia Europe Oceania #&gt; 624 300 396 360 24 barplot(table(gapminder$continent)) In the figures below, we see how factors can be put to work in figures. The continent factor is easily mapped into “facets” or colors and a legend by the ggplot2 package. Making figures with ggplot2 is covered in Chapter ?? so feel free to just sit back and enjoy these plots or blindly copy/paste. ## we exploit the fact that ggplot2 was installed and loaded via the tidyverse p &lt;- ggplot(filter(gapminder, continent != &quot;Oceania&quot;), aes(x = gdpPercap, y = lifeExp)) # just initializes p &lt;- p + scale_x_log10() # log the x axis the right way p + geom_point() # scatterplot p + geom_point(aes(color = continent)) # map continent to color p + geom_point(alpha = (1/3), size = 3) + geom_smooth(lwd = 3, se = FALSE) #&gt; `geom_smooth()` using method = &#39;gam&#39; and formula &#39;y ~ s(x, bs = &quot;cs&quot;)&#39; p + geom_point(alpha = (1/3), size = 3) + facet_wrap(~ continent) + geom_smooth(lwd = 1.5, se = FALSE) #&gt; `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39; 5.6 Recap Use data frames!!! Use the tidyverse!!! This will provide a special type of data frame called a “tibble” that has nice default printing behavior, among other benefits. When in doubt, str() something or print something. Always understand the basic extent of your data frames: number of rows and columns. Understand what flavor the variables are. Use factors!!! But with intention and care. Do basic statistical and visual sanity checking of each variable. Refer to variables by name, e.g., gapminder$lifeExp, not by column number. Your code will be more robust and readable. "],
["dplyr-intro.html", "Kapitel 6 Introduction to dplyr 6.1 Intro 6.2 Think before you create excerpts of your data … 6.3 Use filter() to subset data row-wise 6.4 Meet the new pipe operator 6.5 Use select() to subset the data on variables or columns. 6.6 Revel in the convenience 6.7 Pure, predictable, pipeable 6.8 Resources", " Kapitel 6 Introduction to dplyr 6.1 Intro dplyr is a package for data manipulation, developed by Hadley Wickham and Romain Francois. It is built to be fast, highly expressive, and open-minded about how your data is stored. It is installed as part of the tidyverse meta-package and, as a core package, it is among those loaded via library(tidyverse). dplyr’s roots are in an earlier package called plyr, which implements the “split-apply-combine” strategy for data analysis (Wickham 2011). Where plyr covers a diverse set of inputs and outputs (e.g., arrays, data frames, lists), dplyr has a laser-like focus on data frames or, in the tidyverse, “tibbles”. dplyr is a package-level treatment of the ddply() function from plyr, because “data frame in, data frame out” proved to be so incredibly important. Have no idea what I’m talking about? Not sure if you care? If you use these base R functions: subset(), apply(), [sl]apply(), tapply(), aggregate(), split(), do.call(), with(), within(), then you should keep reading. Also, if you use for() loops a lot, you might enjoy learning other ways to iterate over rows or groups of rows or variables in a data frame. 6.1.1 Load dplyr and gapminder I choose to load the tidyverse, which will load dplyr, among other packages we use incidentally below. library(tidyverse) #&gt; ── Attaching packages ──────────────────────────── tidyverse 1.3.0 ── #&gt; ✓ ggplot2 3.3.2 ✓ purrr 0.3.4 #&gt; ✓ tibble 3.0.3 ✓ dplyr 1.0.2 #&gt; ✓ tidyr 1.1.2 ✓ stringr 1.4.0 #&gt; ✓ readr 1.3.1 ✓ forcats 0.5.0 #&gt; ── Conflicts ─────────────────────────────── tidyverse_conflicts() ── #&gt; x dplyr::filter() masks stats::filter() #&gt; x dplyr::lag() masks stats::lag() Also load gapminder. library(gapminder) 6.1.2 Say hello to the gapminder tibble The gapminder data frame is a special kind of data frame: a tibble. gapminder #&gt; # A tibble: 1,704 x 6 #&gt; country continent year lifeExp pop gdpPercap #&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 Afghanistan Asia 1952 28.8 8425333 779. #&gt; 2 Afghanistan Asia 1957 30.3 9240934 821. #&gt; 3 Afghanistan Asia 1962 32.0 10267083 853. #&gt; 4 Afghanistan Asia 1967 34.0 11537966 836. #&gt; 5 Afghanistan Asia 1972 36.1 13079460 740. #&gt; 6 Afghanistan Asia 1977 38.4 14880372 786. #&gt; 7 Afghanistan Asia 1982 39.9 12881816 978. #&gt; 8 Afghanistan Asia 1987 40.8 13867957 852. #&gt; 9 Afghanistan Asia 1992 41.7 16317921 649. #&gt; 10 Afghanistan Asia 1997 41.8 22227415 635. #&gt; # … with 1,694 more rows It’s tibble-ness is why we get nice compact printing. For a reminder of the problems with base data frame printing, go type iris in the R Console or, better yet, print a data frame to screen that has lots of columns. Note how gapminder’s class() includes tbl_df; the “tibble” terminology is a nod to this. class(gapminder) #&gt; [1] &quot;tbl_df&quot; &quot;tbl&quot; &quot;data.frame&quot; There will be some functions, like print(), that know about tibbles and do something special. There will others that do not, like summary(). In which case the regular data frame treatment will happen, because every tibble is also a regular data frame. To turn any data frame into a tibble use as_tibble(): as_tibble(iris) #&gt; # A tibble: 150 x 5 #&gt; Sepal.Length Sepal.Width Petal.Length Petal.Width Species #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; #&gt; 1 5.1 3.5 1.4 0.2 setosa #&gt; 2 4.9 3 1.4 0.2 setosa #&gt; 3 4.7 3.2 1.3 0.2 setosa #&gt; 4 4.6 3.1 1.5 0.2 setosa #&gt; 5 5 3.6 1.4 0.2 setosa #&gt; 6 5.4 3.9 1.7 0.4 setosa #&gt; 7 4.6 3.4 1.4 0.3 setosa #&gt; 8 5 3.4 1.5 0.2 setosa #&gt; 9 4.4 2.9 1.4 0.2 setosa #&gt; 10 4.9 3.1 1.5 0.1 setosa #&gt; # … with 140 more rows 6.2 Think before you create excerpts of your data … If you feel the urge to store a little snippet of your data: (canada &lt;- gapminder[241:252, ]) #&gt; # A tibble: 12 x 6 #&gt; country continent year lifeExp pop gdpPercap #&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 Canada Americas 1952 68.8 14785584 11367. #&gt; 2 Canada Americas 1957 70.0 17010154 12490. #&gt; 3 Canada Americas 1962 71.3 18985849 13462. #&gt; 4 Canada Americas 1967 72.1 20819767 16077. #&gt; 5 Canada Americas 1972 72.9 22284500 18971. #&gt; 6 Canada Americas 1977 74.2 23796400 22091. #&gt; 7 Canada Americas 1982 75.8 25201900 22899. #&gt; 8 Canada Americas 1987 76.9 26549700 26627. #&gt; 9 Canada Americas 1992 78.0 28523502 26343. #&gt; 10 Canada Americas 1997 78.6 30305843 28955. #&gt; 11 Canada Americas 2002 79.8 31902268 33329. #&gt; 12 Canada Americas 2007 80.7 33390141 36319. Stop and ask yourself … Do I want to create mini datasets for each level of some factor (or unique combination of several factors) … in order to compute or graph something? If YES, use proper data aggregation techniques or faceting in ggplot2 – don’t subset the data. Or, more realistic, only subset the data as a temporary measure while you develop your elegant code for computing on or visualizing these data subsets. If NO, then maybe you really do need to store a copy of a subset of the data. But seriously consider whether you can achieve your goals by simply using the subset = argument of, e.g., the lm() function, to limit computation to your excerpt of choice. Lots of functions offer a subset = argument! Copies and excerpts of your data clutter your workspace, invite mistakes, and sow general confusion. Avoid whenever possible. Reality can also lie somewhere in between. You will find the workflows presented below can help you accomplish your goals with minimal creation of temporary, intermediate objects. 6.3 Use filter() to subset data row-wise filter() takes logical expressions and returns the rows for which all are TRUE. filter(gapminder, lifeExp &lt; 29) #&gt; # A tibble: 2 x 6 #&gt; country continent year lifeExp pop gdpPercap #&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 Afghanistan Asia 1952 28.8 8425333 779. #&gt; 2 Rwanda Africa 1992 23.6 7290203 737. filter(gapminder, country == &quot;Rwanda&quot;, year &gt; 1979) #&gt; # A tibble: 6 x 6 #&gt; country continent year lifeExp pop gdpPercap #&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 Rwanda Africa 1982 46.2 5507565 882. #&gt; 2 Rwanda Africa 1987 44.0 6349365 848. #&gt; 3 Rwanda Africa 1992 23.6 7290203 737. #&gt; 4 Rwanda Africa 1997 36.1 7212583 590. #&gt; 5 Rwanda Africa 2002 43.4 7852401 786. #&gt; 6 Rwanda Africa 2007 46.2 8860588 863. filter(gapminder, country %in% c(&quot;Rwanda&quot;, &quot;Afghanistan&quot;)) #&gt; # A tibble: 24 x 6 #&gt; country continent year lifeExp pop gdpPercap #&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 Afghanistan Asia 1952 28.8 8425333 779. #&gt; 2 Afghanistan Asia 1957 30.3 9240934 821. #&gt; 3 Afghanistan Asia 1962 32.0 10267083 853. #&gt; 4 Afghanistan Asia 1967 34.0 11537966 836. #&gt; 5 Afghanistan Asia 1972 36.1 13079460 740. #&gt; 6 Afghanistan Asia 1977 38.4 14880372 786. #&gt; 7 Afghanistan Asia 1982 39.9 12881816 978. #&gt; 8 Afghanistan Asia 1987 40.8 13867957 852. #&gt; 9 Afghanistan Asia 1992 41.7 16317921 649. #&gt; 10 Afghanistan Asia 1997 41.8 22227415 635. #&gt; # … with 14 more rows Compare with some base R code to accomplish the same things: gapminder[gapminder$lifeExp &lt; 29, ] ## repeat `gapminder`, [i, j] indexing is distracting subset(gapminder, country == &quot;Rwanda&quot;) ## almost same as filter; quite nice actually Under no circumstances should you subset your data the way I did at first: excerpt &lt;- gapminder[241:252, ] Why is this a terrible idea? It is not self-documenting. What is so special about rows 241 through 252? It is fragile. This line of code will produce different results if someone changes the row order of gapminder, e.g. sorts the data earlier in the script. filter(gapminder, country == &quot;Canada&quot;) This call explains itself and is fairly robust. 6.4 Meet the new pipe operator Before we go any further, we should exploit the new pipe operator that the tidyverse imports from the magrittr package by Stefan Bache. This is going to change your data analytical life. You no longer need to enact multi-operation commands by nesting them inside each other, like so many Russian nesting dolls. This new syntax leads to code that is much easier to write and to read. Here’s what it looks like: %&gt;%. The RStudio keyboard shortcut: Ctrl+Shift+M (Windows), Cmd+Shift+M (Mac). Let’s demo then I’ll explain. gapminder %&gt;% head() #&gt; # A tibble: 6 x 6 #&gt; country continent year lifeExp pop gdpPercap #&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 Afghanistan Asia 1952 28.8 8425333 779. #&gt; 2 Afghanistan Asia 1957 30.3 9240934 821. #&gt; 3 Afghanistan Asia 1962 32.0 10267083 853. #&gt; 4 Afghanistan Asia 1967 34.0 11537966 836. #&gt; 5 Afghanistan Asia 1972 36.1 13079460 740. #&gt; 6 Afghanistan Asia 1977 38.4 14880372 786. This is equivalent to head(gapminder). The pipe operator takes the thing on the left-hand-side and pipes it into the function call on the right-hand-side – literally, drops it in as the first argument. Never fear, you can still specify other arguments to this function! To see the first 3 rows of gapminder, we could say head(gapminder, 3) or this: gapminder %&gt;% head(3) #&gt; # A tibble: 3 x 6 #&gt; country continent year lifeExp pop gdpPercap #&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 Afghanistan Asia 1952 28.8 8425333 779. #&gt; 2 Afghanistan Asia 1957 30.3 9240934 821. #&gt; 3 Afghanistan Asia 1962 32.0 10267083 853. I’ve advised you to think “gets” whenever you see the assignment operator, &lt;-. Similarly, you should think “then” whenever you see the pipe operator, %&gt;%. You are probably not impressed yet, but the magic will soon happen. 6.5 Use select() to subset the data on variables or columns. Back to dplyr…. Use select() to subset the data on variables or columns. Here’s a conventional call: select(gapminder, year, lifeExp) #&gt; # A tibble: 1,704 x 2 #&gt; year lifeExp #&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 1952 28.8 #&gt; 2 1957 30.3 #&gt; 3 1962 32.0 #&gt; 4 1967 34.0 #&gt; 5 1972 36.1 #&gt; 6 1977 38.4 #&gt; 7 1982 39.9 #&gt; 8 1987 40.8 #&gt; 9 1992 41.7 #&gt; 10 1997 41.8 #&gt; # … with 1,694 more rows And here’s the same operation, but written with the pipe operator and piped through head(): gapminder %&gt;% select(year, lifeExp) %&gt;% head(4) #&gt; # A tibble: 4 x 2 #&gt; year lifeExp #&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 1952 28.8 #&gt; 2 1957 30.3 #&gt; 3 1962 32.0 #&gt; 4 1967 34.0 Think: “Take gapminder, then select the variables year and lifeExp, then show the first 4 rows.” 6.6 Revel in the convenience Here’s the data for Cambodia, but only certain variables: gapminder %&gt;% filter(country == &quot;Cambodia&quot;) %&gt;% select(year, lifeExp) #&gt; # A tibble: 12 x 2 #&gt; year lifeExp #&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 1952 39.4 #&gt; 2 1957 41.4 #&gt; 3 1962 43.4 #&gt; 4 1967 45.4 #&gt; 5 1972 40.3 #&gt; 6 1977 31.2 #&gt; 7 1982 51.0 #&gt; 8 1987 53.9 #&gt; 9 1992 55.8 #&gt; 10 1997 56.5 #&gt; 11 2002 56.8 #&gt; 12 2007 59.7 and what a typical base R call would look like: gapminder[gapminder$country == &quot;Cambodia&quot;, c(&quot;year&quot;, &quot;lifeExp&quot;)] #&gt; # A tibble: 12 x 2 #&gt; year lifeExp #&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 1952 39.4 #&gt; 2 1957 41.4 #&gt; 3 1962 43.4 #&gt; 4 1967 45.4 #&gt; 5 1972 40.3 #&gt; 6 1977 31.2 #&gt; 7 1982 51.0 #&gt; 8 1987 53.9 #&gt; 9 1992 55.8 #&gt; 10 1997 56.5 #&gt; 11 2002 56.8 #&gt; 12 2007 59.7 6.7 Pure, predictable, pipeable We’ve barely scratched the surface of dplyr but I want to point out key principles you may start to appreciate. If you’re new to R or “programming with data”, feel free skip this section and move on. dplyr’s verbs, such as filter() and select(), are what’s called pure functions. To quote from the Functions chapter of Wickham’s Advanced R book (2015): The functions that are the easiest to understand and reason about are pure functions: functions that always map the same input to the same output and have no other impact on the workspace. In other words, pure functions have no side effects: they don’t affect the state of the world in any way apart from the value they return. In fact, these verbs are a special case of pure functions: they take the same flavor of object as input and output. Namely, a data frame or one of the other data receptacles dplyr supports. And finally, the data is always the very first argument of the verb functions. This set of deliberate design choices, together with the new pipe operator, produces a highly effective, low friction domain-specific language for data analysis. Go to the next Chapter, dplyr functions for a single dataset, for more dplyr! 6.8 Resources dplyr official stuff: Package home on CRAN. Note there are several vignettes, with the Introduction to dplyr being the most relevant right now. The Window functions one will also be interesting to you now. Development home on GitHub. Tutorial HW delivered (note this links to a DropBox folder) at useR! 2014 conference. RStudio Data Transformation Cheat Sheet, covering dplyr. Remember you can get to these via Help &gt; Cheatsheets. Data transformation chapter of R for Data Science (Wickham and Grolemund 2016). “Let the Data Flow: Pipelines in R with dplyr and magrittr” - Excellent slides on pipelines and dplyr by TJ Mahr, talk given to the Madison R Users Group. Blog post “Hands-on dplyr tutorial for faster data manipulation in R” by Data School, that includes a link to an R Markdown document and links to videos. Chapter ?? - cheatsheet I made for dplyr join functions (not relevant yet but soon). "],
["dplyr-single.html", "Kapitel 7 Single table dplyr functions 7.1 Where were we? 7.2 Load dplyr and gapminder 7.3 Create a copy of gapminder 7.4 Use mutate() to add new variables 7.5 Use arrange() to row-order data in a principled way 7.6 Use rename() to rename variables 7.7 select() can rename and reposition variables 7.8 group_by() is a mighty weapon 7.9 Grouped mutate 7.10 Grand Finale 7.11 Resources", " Kapitel 7 Single table dplyr functions 7.1 Where were we? In Chapter 6, Introduction to dplyr, we used two very important verbs and an operator: filter() for subsetting data with row logic select() for subsetting data variable- or column-wise the pipe operator %&gt;%, which feeds the LHS as the first argument to the expression on the RHS We also discussed dplyr’s role inside the tidyverse and tibbles: dplyr is a core package in the tidyverse meta-package. Since we often make incidental usage of the others, we will load dplyr and the others via library(tidyverse). The tidyverse embraces a special flavor of data frame, called a tibble. The gapminder dataset is stored as a tibble. 7.2 Load dplyr and gapminder I choose to load the tidyverse, which will load dplyr, among other packages we use incidentally below. library(tidyverse) #&gt; ── Attaching packages ──────────────────────────── tidyverse 1.3.0 ── #&gt; ✓ ggplot2 3.3.2 ✓ purrr 0.3.4 #&gt; ✓ tibble 3.0.3 ✓ dplyr 1.0.2 #&gt; ✓ tidyr 1.1.2 ✓ stringr 1.4.0 #&gt; ✓ readr 1.3.1 ✓ forcats 0.5.0 #&gt; ── Conflicts ─────────────────────────────── tidyverse_conflicts() ── #&gt; x dplyr::filter() masks stats::filter() #&gt; x dplyr::lag() masks stats::lag() Also load gapminder. library(gapminder) 7.3 Create a copy of gapminder We’re going to make changes to the gapminder tibble. To eliminate any fear that you’re damaging the data that comes with the package, we create an explicit copy of gapminder for our experiments. (my_gap &lt;- gapminder) #&gt; # A tibble: 1,704 x 6 #&gt; country continent year lifeExp pop gdpPercap #&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 Afghanistan Asia 1952 28.8 8425333 779. #&gt; 2 Afghanistan Asia 1957 30.3 9240934 821. #&gt; 3 Afghanistan Asia 1962 32.0 10267083 853. #&gt; 4 Afghanistan Asia 1967 34.0 11537966 836. #&gt; 5 Afghanistan Asia 1972 36.1 13079460 740. #&gt; 6 Afghanistan Asia 1977 38.4 14880372 786. #&gt; 7 Afghanistan Asia 1982 39.9 12881816 978. #&gt; 8 Afghanistan Asia 1987 40.8 13867957 852. #&gt; 9 Afghanistan Asia 1992 41.7 16317921 649. #&gt; 10 Afghanistan Asia 1997 41.8 22227415 635. #&gt; # … with 1,694 more rows Pay close attention to when we evaluate statements but let the output just print to screen: ## let output print to screen, but do not store my_gap %&gt;% filter(country == &quot;Canada&quot;) … versus when we assign the output to an object, possibly overwriting an existing object. ## store the output as an R object my_precious &lt;- my_gap %&gt;% filter(country == &quot;Canada&quot;) 7.4 Use mutate() to add new variables Imagine we wanted to recover each country’s GDP. After all, the Gapminder data has a variable for population and GDP per capita. Let’s multiply them together. mutate() is a function that defines and inserts new variables into a tibble. You can refer to existing variables by name. my_gap %&gt;% mutate(gdp = pop * gdpPercap) #&gt; # A tibble: 1,704 x 7 #&gt; country continent year lifeExp pop gdpPercap gdp #&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Afghanistan Asia 1952 28.8 8425333 779. 6567086330. #&gt; 2 Afghanistan Asia 1957 30.3 9240934 821. 7585448670. #&gt; 3 Afghanistan Asia 1962 32.0 10267083 853. 8758855797. #&gt; 4 Afghanistan Asia 1967 34.0 11537966 836. 9648014150. #&gt; 5 Afghanistan Asia 1972 36.1 13079460 740. 9678553274. #&gt; 6 Afghanistan Asia 1977 38.4 14880372 786. 11697659231. #&gt; 7 Afghanistan Asia 1982 39.9 12881816 978. 12598563401. #&gt; 8 Afghanistan Asia 1987 40.8 13867957 852. 11820990309. #&gt; 9 Afghanistan Asia 1992 41.7 16317921 649. 10595901589. #&gt; 10 Afghanistan Asia 1997 41.8 22227415 635. 14121995875. #&gt; # … with 1,694 more rows Hmmmm … those GDP numbers are almost uselessly large and abstract. Consider the advice of Randall Munroe of xkcd: One thing that bothers me is large numbers presented without context… “If I added a zero to this number, would the sentence containing it mean something different to me?” If the answer is “no”, maybe the number has no business being in the sentence in the first place. Maybe it would be more meaningful to consumers of my tables and figures to stick with GDP per capita. But what if I reported GDP per capita, relative to some benchmark country. Since Canada is my adopted home, I’ll go with that. I need to create a new variable that is gdpPercap divided by Canadian gdpPercap, taking care that I always divide two numbers that pertain to the same year. How I achieve this: Filter down to the rows for Canada. Create a new temporary variable in my_gap: Extract the gdpPercap variable from the Canadian data. Replicate it once per country in the dataset, so it has the right length. Divide raw gdpPercap by this Canadian figure. Discard the temporary variable of replicated Canadian gdpPercap. ctib &lt;- my_gap %&gt;% filter(country == &quot;Canada&quot;) ## this is a semi-dangerous way to add this variable ## I&#39;d prefer to join on year, but we haven&#39;t covered joins yet my_gap &lt;- my_gap %&gt;% mutate(tmp = rep(ctib$gdpPercap, nlevels(country)), gdpPercapRel = gdpPercap / tmp, tmp = NULL) Note that, mutate() builds new variables sequentially so you can reference earlier ones (like tmp) when defining later ones (like gdpPercapRel). Also, you can get rid of a variable by setting it to NULL. How could we sanity check that this worked? The Canadian values for gdpPercapRel better all be 1! my_gap %&gt;% filter(country == &quot;Canada&quot;) %&gt;% select(country, year, gdpPercapRel) #&gt; # A tibble: 12 x 3 #&gt; country year gdpPercapRel #&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 Canada 1952 1 #&gt; 2 Canada 1957 1 #&gt; 3 Canada 1962 1 #&gt; 4 Canada 1967 1 #&gt; 5 Canada 1972 1 #&gt; 6 Canada 1977 1 #&gt; 7 Canada 1982 1 #&gt; 8 Canada 1987 1 #&gt; 9 Canada 1992 1 #&gt; 10 Canada 1997 1 #&gt; 11 Canada 2002 1 #&gt; 12 Canada 2007 1 I perceive Canada to be a “high GDP” country, so I predict that the distribution of gdpPercapRel is located below 1, possibly even well below. Check your intuition! summary(my_gap$gdpPercapRel) #&gt; Min. 1st Qu. Median Mean 3rd Qu. Max. #&gt; 0.01 0.06 0.17 0.33 0.45 9.53 The relative GDP per capita numbers are, in general, well below 1. We see that most of the countries covered by this dataset have substantially lower GDP per capita, relative to Canada, across the entire time period. Remember: Trust No One. Including (especially?) yourself. Always try to find a way to check that you’ve done what meant to. Prepare to be horrified. 7.5 Use arrange() to row-order data in a principled way arrange() reorders the rows in a data frame. Imagine you wanted this data ordered by year then country, as opposed to by country then year. my_gap %&gt;% arrange(year, country) #&gt; # A tibble: 1,704 x 7 #&gt; country continent year lifeExp pop gdpPercap gdpPercapRel #&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Afghanistan Asia 1952 28.8 8425333 779. 0.0686 #&gt; 2 Albania Europe 1952 55.2 1282697 1601. 0.141 #&gt; 3 Algeria Africa 1952 43.1 9279525 2449. 0.215 #&gt; 4 Angola Africa 1952 30.0 4232095 3521. 0.310 #&gt; 5 Argentina Americas 1952 62.5 17876956 5911. 0.520 #&gt; 6 Australia Oceania 1952 69.1 8691212 10040. 0.883 #&gt; 7 Austria Europe 1952 66.8 6927772 6137. 0.540 #&gt; 8 Bahrain Asia 1952 50.9 120447 9867. 0.868 #&gt; 9 Bangladesh Asia 1952 37.5 46886859 684. 0.0602 #&gt; 10 Belgium Europe 1952 68 8730405 8343. 0.734 #&gt; # … with 1,694 more rows Or maybe you want just the data from 2007, sorted on life expectancy? my_gap %&gt;% filter(year == 2007) %&gt;% arrange(lifeExp) #&gt; # A tibble: 142 x 7 #&gt; country continent year lifeExp pop gdpPercap gdpPercapRel #&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Swaziland Africa 2007 39.6 1.13e6 4513. 0.124 #&gt; 2 Mozambique Africa 2007 42.1 2.00e7 824. 0.0227 #&gt; 3 Zambia Africa 2007 42.4 1.17e7 1271. 0.0350 #&gt; 4 Sierra Leone Africa 2007 42.6 6.14e6 863. 0.0237 #&gt; 5 Lesotho Africa 2007 42.6 2.01e6 1569. 0.0432 #&gt; 6 Angola Africa 2007 42.7 1.24e7 4797. 0.132 #&gt; 7 Zimbabwe Africa 2007 43.5 1.23e7 470. 0.0129 #&gt; 8 Afghanistan Asia 2007 43.8 3.19e7 975. 0.0268 #&gt; 9 Central African Repub… Africa 2007 44.7 4.37e6 706. 0.0194 #&gt; 10 Liberia Africa 2007 45.7 3.19e6 415. 0.0114 #&gt; # … with 132 more rows Oh, you’d like to sort on life expectancy in descending order? Then use desc(). my_gap %&gt;% filter(year == 2007) %&gt;% arrange(desc(lifeExp)) #&gt; # A tibble: 142 x 7 #&gt; country continent year lifeExp pop gdpPercap gdpPercapRel #&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Japan Asia 2007 82.6 127467972 31656. 0.872 #&gt; 2 Hong Kong, China Asia 2007 82.2 6980412 39725. 1.09 #&gt; 3 Iceland Europe 2007 81.8 301931 36181. 0.996 #&gt; 4 Switzerland Europe 2007 81.7 7554661 37506. 1.03 #&gt; 5 Australia Oceania 2007 81.2 20434176 34435. 0.948 #&gt; 6 Spain Europe 2007 80.9 40448191 28821. 0.794 #&gt; 7 Sweden Europe 2007 80.9 9031088 33860. 0.932 #&gt; 8 Israel Asia 2007 80.7 6426679 25523. 0.703 #&gt; 9 France Europe 2007 80.7 61083916 30470. 0.839 #&gt; 10 Canada Americas 2007 80.7 33390141 36319. 1 #&gt; # … with 132 more rows I advise that your analyses NEVER rely on rows or variables being in a specific order. But it’s still true that human beings write the code and the interactive development process can be much nicer if you reorder the rows of your data as you go along. Also, once you are preparing tables for human eyeballs, it is imperative that you step up and take control of row order. 7.6 Use rename() to rename variables When I first cleaned this Gapminder excerpt, I was a camelCase person, but now I’m all about snake_case. So I am vexed by the variable names I chose when I cleaned this data years ago. Let’s rename some variables! my_gap %&gt;% rename(life_exp = lifeExp, gdp_percap = gdpPercap, gdp_percap_rel = gdpPercapRel) #&gt; # A tibble: 1,704 x 7 #&gt; country continent year life_exp pop gdp_percap gdp_percap_rel #&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Afghanistan Asia 1952 28.8 8425333 779. 0.0686 #&gt; 2 Afghanistan Asia 1957 30.3 9240934 821. 0.0657 #&gt; 3 Afghanistan Asia 1962 32.0 10267083 853. 0.0634 #&gt; 4 Afghanistan Asia 1967 34.0 11537966 836. 0.0520 #&gt; 5 Afghanistan Asia 1972 36.1 13079460 740. 0.0390 #&gt; 6 Afghanistan Asia 1977 38.4 14880372 786. 0.0356 #&gt; 7 Afghanistan Asia 1982 39.9 12881816 978. 0.0427 #&gt; 8 Afghanistan Asia 1987 40.8 13867957 852. 0.0320 #&gt; 9 Afghanistan Asia 1992 41.7 16317921 649. 0.0246 #&gt; 10 Afghanistan Asia 1997 41.8 22227415 635. 0.0219 #&gt; # … with 1,694 more rows I did NOT assign the post-rename object back to my_gap because that would make the chunks in this tutorial harder to copy/paste and run out of order. In real life, I would probably assign this back to my_gap, in a data preparation script, and proceed with the new variable names. 7.7 select() can rename and reposition variables You’ve seen simple use of select(). There are two tricks you might enjoy: select() can rename the variables you request to keep. select() can be used with everything() to hoist a variable up to the front of the tibble. my_gap %&gt;% filter(country == &quot;Burundi&quot;, year &gt; 1996) %&gt;% select(yr = year, lifeExp, gdpPercap) %&gt;% select(gdpPercap, everything()) #&gt; # A tibble: 3 x 3 #&gt; gdpPercap yr lifeExp #&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 463. 1997 45.3 #&gt; 2 446. 2002 47.4 #&gt; 3 430. 2007 49.6 everything() is one of several helpers for variable selection. Read its help to see the rest. 7.8 group_by() is a mighty weapon I have found that friends and family collaborators love to ask seemingly innocuous questions like, “which country experienced the sharpest 5-year drop in life expectancy?”. In fact, that is a totally natural question to ask. But if you are using a language that doesn’t know about data, it’s an incredibly annoying question to answer. dplyr offers powerful tools to solve this class of problem: group_by() adds extra structure to your dataset – grouping information – which lays the groundwork for computations within the groups. summarize() takes a dataset with \\(n\\) observations, computes requested summaries, and returns a dataset with 1 observation. Window functions take a dataset with \\(n\\) observations and return a dataset with \\(n\\) observations. mutate() and summarize() will honor groups. You can also do very general computations on your groups with do(), though elsewhere in this course, I advocate for other approaches that I find more intuitive, using the purrr package. Combined with the verbs you already know, these new tools allow you to solve an extremely diverse set of problems with relative ease. 7.8.1 Counting things up Let’s start with simple counting. How many observations do we have per continent? my_gap %&gt;% group_by(continent) %&gt;% summarize(n = n()) #&gt; `summarise()` ungrouping output (override with `.groups` argument) #&gt; # A tibble: 5 x 2 #&gt; continent n #&gt; &lt;fct&gt; &lt;int&gt; #&gt; 1 Africa 624 #&gt; 2 Americas 300 #&gt; 3 Asia 396 #&gt; 4 Europe 360 #&gt; 5 Oceania 24 Let us pause here to think about the tidyverse. You could get these same frequencies using table() from base R. table(gapminder$continent) #&gt; #&gt; Africa Americas Asia Europe Oceania #&gt; 624 300 396 360 24 str(table(gapminder$continent)) #&gt; &#39;table&#39; int [1:5(1d)] 624 300 396 360 24 #&gt; - attr(*, &quot;dimnames&quot;)=List of 1 #&gt; ..$ : chr [1:5] &quot;Africa&quot; &quot;Americas&quot; &quot;Asia&quot; &quot;Europe&quot; ... But the object of class table that is returned makes downstream computation a bit fiddlier than you’d like. For example, it’s too bad the continent levels come back only as names and not as a proper factor, with the original set of levels. This is an example of how the tidyverse smooths transitions where you want the output of step i to become the input of step i + 1. The tally() function is a convenience function that knows to count rows. It honors groups. my_gap %&gt;% group_by(continent) %&gt;% tally() #&gt; # A tibble: 5 x 2 #&gt; continent n #&gt; &lt;fct&gt; &lt;int&gt; #&gt; 1 Africa 624 #&gt; 2 Americas 300 #&gt; 3 Asia 396 #&gt; 4 Europe 360 #&gt; 5 Oceania 24 The count() function is an even more convenient function that does both grouping and counting. my_gap %&gt;% count(continent) #&gt; # A tibble: 5 x 2 #&gt; continent n #&gt; &lt;fct&gt; &lt;int&gt; #&gt; 1 Africa 624 #&gt; 2 Americas 300 #&gt; 3 Asia 396 #&gt; 4 Europe 360 #&gt; 5 Oceania 24 What if we wanted to add the number of unique countries for each continent? You can compute multiple summaries inside summarize(). Use the n_distinct() function to count the number of distinct countries within each continent. my_gap %&gt;% group_by(continent) %&gt;% summarize(n = n(), n_countries = n_distinct(country)) #&gt; `summarise()` ungrouping output (override with `.groups` argument) #&gt; # A tibble: 5 x 3 #&gt; continent n n_countries #&gt; &lt;fct&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 Africa 624 52 #&gt; 2 Americas 300 25 #&gt; 3 Asia 396 33 #&gt; 4 Europe 360 30 #&gt; 5 Oceania 24 2 7.8.2 General summarization The functions you’ll apply within summarize() include classical statistical summaries, like mean(), median(), var(), sd(), mad(), IQR(), min(), and max(). Remember they are functions that take \\(n\\) inputs and distill them down into 1 output. Although this may be statistically ill-advised, let’s compute the average life expectancy by continent. my_gap %&gt;% group_by(continent) %&gt;% summarize(avg_lifeExp = mean(lifeExp)) #&gt; `summarise()` ungrouping output (override with `.groups` argument) #&gt; # A tibble: 5 x 2 #&gt; continent avg_lifeExp #&gt; &lt;fct&gt; &lt;dbl&gt; #&gt; 1 Africa 48.9 #&gt; 2 Americas 64.7 #&gt; 3 Asia 60.1 #&gt; 4 Europe 71.9 #&gt; 5 Oceania 74.3 summarize_at() applies the same summary function(s) to multiple variables. Let’s compute average and median life expectancy and GDP per capita by continent by year…but only for 1952 and 2007. my_gap %&gt;% filter(year %in% c(1952, 2007)) %&gt;% group_by(continent, year) %&gt;% summarize_at(vars(lifeExp, gdpPercap), list(~mean(.), ~median(.))) #&gt; # A tibble: 10 x 6 #&gt; # Groups: continent [5] #&gt; continent year lifeExp_mean gdpPercap_mean lifeExp_median gdpPercap_median #&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Africa 1952 39.1 1253. 38.8 987. #&gt; 2 Africa 2007 54.8 3089. 52.9 1452. #&gt; 3 Americas 1952 53.3 4079. 54.7 3048. #&gt; 4 Americas 2007 73.6 11003. 72.9 8948. #&gt; 5 Asia 1952 46.3 5195. 44.9 1207. #&gt; 6 Asia 2007 70.7 12473. 72.4 4471. #&gt; 7 Europe 1952 64.4 5661. 65.9 5142. #&gt; 8 Europe 2007 77.6 25054. 78.6 28054. #&gt; 9 Oceania 1952 69.3 10298. 69.3 10298. #&gt; 10 Oceania 2007 80.7 29810. 80.7 29810. Let’s focus just on Asia. What are the minimum and maximum life expectancies seen by year? my_gap %&gt;% filter(continent == &quot;Asia&quot;) %&gt;% group_by(year) %&gt;% summarize(min_lifeExp = min(lifeExp), max_lifeExp = max(lifeExp)) #&gt; `summarise()` ungrouping output (override with `.groups` argument) #&gt; # A tibble: 12 x 3 #&gt; year min_lifeExp max_lifeExp #&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1952 28.8 65.4 #&gt; 2 1957 30.3 67.8 #&gt; 3 1962 32.0 69.4 #&gt; 4 1967 34.0 71.4 #&gt; 5 1972 36.1 73.4 #&gt; 6 1977 31.2 75.4 #&gt; 7 1982 39.9 77.1 #&gt; 8 1987 40.8 78.7 #&gt; 9 1992 41.7 79.4 #&gt; 10 1997 41.8 80.7 #&gt; 11 2002 42.1 82 #&gt; 12 2007 43.8 82.6 Of course it would be much more interesting to see which country contributed these extreme observations. Is the minimum (maximum) always coming from the same country? We tackle that with window functions shortly. 7.9 Grouped mutate Sometimes you don’t want to collapse the \\(n\\) rows for each group into one row. You want to keep your groups, but compute within them. 7.9.1 Computing with group-wise summaries Let’s make a new variable that is the years of life expectancy gained (lost) relative to 1952, for each individual country. We group by country and use mutate() to make a new variable. The first() function extracts the first value from a vector. Notice that first() is operating on the vector of life expectancies within each country group. my_gap %&gt;% group_by(country) %&gt;% select(country, year, lifeExp) %&gt;% mutate(lifeExp_gain = lifeExp - first(lifeExp)) %&gt;% filter(year &lt; 1963) #&gt; # A tibble: 426 x 4 #&gt; # Groups: country [142] #&gt; country year lifeExp lifeExp_gain #&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Afghanistan 1952 28.8 0 #&gt; 2 Afghanistan 1957 30.3 1.53 #&gt; 3 Afghanistan 1962 32.0 3.20 #&gt; 4 Albania 1952 55.2 0 #&gt; 5 Albania 1957 59.3 4.05 #&gt; 6 Albania 1962 64.8 9.59 #&gt; 7 Algeria 1952 43.1 0 #&gt; 8 Algeria 1957 45.7 2.61 #&gt; 9 Algeria 1962 48.3 5.23 #&gt; 10 Angola 1952 30.0 0 #&gt; # … with 416 more rows Within country, we take the difference between life expectancy in year \\(i\\) and life expectancy in 1952. Therefore we always see zeroes for 1952 and, for most countries, a sequence of positive and increasing numbers. 7.9.2 Window functions Window functions take \\(n\\) inputs and give back \\(n\\) outputs. Furthermore, the output depends on all the values. So rank() is a window function but log() is not. Here we use window functions based on ranks and offsets. Let’s revisit the worst and best life expectancies in Asia over time, but retaining info about which country contributes these extreme values. my_gap %&gt;% filter(continent == &quot;Asia&quot;) %&gt;% select(year, country, lifeExp) %&gt;% group_by(year) %&gt;% filter(min_rank(desc(lifeExp)) &lt; 2 | min_rank(lifeExp) &lt; 2) %&gt;% arrange(year) %&gt;% print(n = Inf) #&gt; # A tibble: 24 x 3 #&gt; # Groups: year [12] #&gt; year country lifeExp #&gt; &lt;int&gt; &lt;fct&gt; &lt;dbl&gt; #&gt; 1 1952 Afghanistan 28.8 #&gt; 2 1952 Israel 65.4 #&gt; 3 1957 Afghanistan 30.3 #&gt; 4 1957 Israel 67.8 #&gt; 5 1962 Afghanistan 32.0 #&gt; 6 1962 Israel 69.4 #&gt; 7 1967 Afghanistan 34.0 #&gt; 8 1967 Japan 71.4 #&gt; 9 1972 Afghanistan 36.1 #&gt; 10 1972 Japan 73.4 #&gt; 11 1977 Cambodia 31.2 #&gt; 12 1977 Japan 75.4 #&gt; 13 1982 Afghanistan 39.9 #&gt; 14 1982 Japan 77.1 #&gt; 15 1987 Afghanistan 40.8 #&gt; 16 1987 Japan 78.7 #&gt; 17 1992 Afghanistan 41.7 #&gt; 18 1992 Japan 79.4 #&gt; 19 1997 Afghanistan 41.8 #&gt; 20 1997 Japan 80.7 #&gt; 21 2002 Afghanistan 42.1 #&gt; 22 2002 Japan 82 #&gt; 23 2007 Afghanistan 43.8 #&gt; 24 2007 Japan 82.6 We see that (min = Afghanistan, max = Japan) is the most frequent result, but Cambodia and Israel pop up at least once each as the min or max, respectively. That table should make you impatient for our upcoming work on tidying and reshaping data! Wouldn’t it be nice to have one row per year? How did that actually work? First, I store and view a partial that leaves off the filter() statement. All of these operations should be familiar. asia &lt;- my_gap %&gt;% filter(continent == &quot;Asia&quot;) %&gt;% select(year, country, lifeExp) %&gt;% group_by(year) asia #&gt; # A tibble: 396 x 3 #&gt; # Groups: year [12] #&gt; year country lifeExp #&gt; &lt;int&gt; &lt;fct&gt; &lt;dbl&gt; #&gt; 1 1952 Afghanistan 28.8 #&gt; 2 1957 Afghanistan 30.3 #&gt; 3 1962 Afghanistan 32.0 #&gt; 4 1967 Afghanistan 34.0 #&gt; 5 1972 Afghanistan 36.1 #&gt; 6 1977 Afghanistan 38.4 #&gt; 7 1982 Afghanistan 39.9 #&gt; 8 1987 Afghanistan 40.8 #&gt; 9 1992 Afghanistan 41.7 #&gt; 10 1997 Afghanistan 41.8 #&gt; # … with 386 more rows Now we apply a window function – min_rank(). Since asia is grouped by year, min_rank() operates within mini-datasets, each for a specific year. Applied to the variable lifeExp, min_rank() returns the rank of each country’s observed life expectancy. FYI, the min part just specifies how ties are broken. Here is an explicit peek at these within-year life expectancy ranks, in both the (default) ascending and descending order. For concreteness, I use mutate() to actually create these variables, even though I dropped this in the solution above. Let’s look at a bit of that. asia %&gt;% mutate(le_rank = min_rank(lifeExp), le_desc_rank = min_rank(desc(lifeExp))) %&gt;% filter(country %in% c(&quot;Afghanistan&quot;, &quot;Japan&quot;, &quot;Thailand&quot;), year &gt; 1995) #&gt; # A tibble: 9 x 5 #&gt; # Groups: year [3] #&gt; year country lifeExp le_rank le_desc_rank #&gt; &lt;int&gt; &lt;fct&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 1997 Afghanistan 41.8 1 33 #&gt; 2 2002 Afghanistan 42.1 1 33 #&gt; 3 2007 Afghanistan 43.8 1 33 #&gt; 4 1997 Japan 80.7 33 1 #&gt; 5 2002 Japan 82 33 1 #&gt; 6 2007 Japan 82.6 33 1 #&gt; 7 1997 Thailand 67.5 12 22 #&gt; 8 2002 Thailand 68.6 12 22 #&gt; 9 2007 Thailand 70.6 12 22 Afghanistan tends to present 1’s in the le_rank variable, Japan tends to present 1’s in the le_desc_rank variable and other countries, like Thailand, present less extreme ranks. You can understand the original filter() statement now: filter(min_rank(desc(lifeExp)) &lt; 2 | min_rank(lifeExp) &lt; 2) These two sets of ranks are formed on-the-fly, within year group, and filter() retains rows with rank less than 2, which means … the row with rank = 1. Since we do for ascending and descending ranks, we get both the min and the max. If we had wanted just the min OR the max, an alternative approach using top_n() would have worked. my_gap %&gt;% filter(continent == &quot;Asia&quot;) %&gt;% select(year, country, lifeExp) %&gt;% arrange(year) %&gt;% group_by(year) %&gt;% #top_n(1, wt = lifeExp) ## gets the min top_n(1, wt = desc(lifeExp)) ## gets the max #&gt; # A tibble: 12 x 3 #&gt; # Groups: year [12] #&gt; year country lifeExp #&gt; &lt;int&gt; &lt;fct&gt; &lt;dbl&gt; #&gt; 1 1952 Afghanistan 28.8 #&gt; 2 1957 Afghanistan 30.3 #&gt; 3 1962 Afghanistan 32.0 #&gt; 4 1967 Afghanistan 34.0 #&gt; 5 1972 Afghanistan 36.1 #&gt; 6 1977 Cambodia 31.2 #&gt; 7 1982 Afghanistan 39.9 #&gt; 8 1987 Afghanistan 40.8 #&gt; 9 1992 Afghanistan 41.7 #&gt; 10 1997 Afghanistan 41.8 #&gt; 11 2002 Afghanistan 42.1 #&gt; 12 2007 Afghanistan 43.8 7.10 Grand Finale So let’s answer that “simple” question: which country experienced the sharpest 5-year drop in life expectancy? Recall that this excerpt of the Gapminder data only has data every five years, e.g. for 1952, 1957, etc. So this really means looking at life expectancy changes between adjacent timepoints. At this point, that’s just too easy, so let’s do it by continent while we’re at it. my_gap %&gt;% select(country, year, continent, lifeExp) %&gt;% group_by(continent, country) %&gt;% ## within country, take (lifeExp in year i) - (lifeExp in year i - 1) ## positive means lifeExp went up, negative means it went down mutate(le_delta = lifeExp - lag(lifeExp)) %&gt;% ## within country, retain the worst lifeExp change = smallest or most negative summarize(worst_le_delta = min(le_delta, na.rm = TRUE)) %&gt;% ## within continent, retain the row with the lowest worst_le_delta top_n(-1, wt = worst_le_delta) %&gt;% arrange(worst_le_delta) #&gt; `summarise()` regrouping output by &#39;continent&#39; (override with `.groups` argument) #&gt; # A tibble: 5 x 3 #&gt; # Groups: continent [5] #&gt; continent country worst_le_delta #&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; #&gt; 1 Africa Rwanda -20.4 #&gt; 2 Asia Cambodia -9.10 #&gt; 3 Americas El Salvador -1.51 #&gt; 4 Europe Montenegro -1.46 #&gt; 5 Oceania Australia 0.170 Ponder that for a while. The subject matter and the code. Mostly you’re seeing what genocide looks like in dry statistics on average life expectancy. Break the code into pieces, starting at the top, and inspect the intermediate results. That’s certainly how I was able to write such a thing. These commands do not leap fully formed out of anyone’s forehead – they are built up gradually, with lots of errors and refinements along the way. I’m not even sure it’s a great idea to do so much manipulation in one fell swoop. Is the statement above really hard for you to read? If yes, then by all means break it into pieces and make some intermediate objects. Your code should be easy to write and read when you’re done. In later tutorials, we’ll explore more of dplyr, such as operations based on two datasets. 7.11 Resources dplyr official stuff: Package home on CRAN. Note there are several vignettes, with the Introduction to dplyr being the most relevant right now. The Window functions one will also be interesting to you now. Development home on GitHub. Tutorial HW delivered (note this links to a DropBox folder) at useR! 2014 conference. RStudio Data Transformation Cheat Sheet, covering dplyr. Remember you can get to these via Help &gt; Cheatsheets. Data transformation chapter of R for Data Science (Wickham and Grolemund 2016). “Let the Data Flow: Pipelines in R with dplyr and magrittr” - Excellent slides on pipelines and dplyr by TJ Mahr, talk given to the Madison R Users Group. Blog post “Hands-on dplyr tutorial for faster data manipulation in R” by Data School, that includes a link to an R Markdown document and links to videos. Chapter ?? - cheatsheet I made for dplyr join functions (not relevant yet but soon). "],
["tidy-data.html", "Kapitel 8 Tidy data", " Kapitel 8 Tidy data Tidy data using Lord of the Rings: tidy data, tidyr. "],
["import-export.html", "Kapitel 9 Writing and reading files 9.1 File I/O overview 9.2 Load the tidyverse 9.3 Locate the Gapminder data 9.4 Bring rectangular data in 9.5 Compute something worthy of export 9.6 Write rectangular data out 9.7 Invertibility 9.8 Reordering the levels of the country factor 9.9 saveRDS() and readRDS() 9.10 Retaining factor levels upon re-import 9.11 dput() and dget() 9.12 Other types of objects to use dput() or saveRDS() on 9.13 Clean up 9.14 Pitfalls of delimited files 9.15 Resources", " Kapitel 9 Writing and reading files 9.1 File I/O overview We’ve been loading the Gapminder data as a data frame from the gapminder data package. We haven’t been explicitly writing any data or derived results to file. In real life, you’ll bring rectangular data into and out of R all the time. Sometimes you’ll need to do same for non-rectangular objects. How do you do this? What issues should you think about? 9.1.1 Data import mindset Data import generally feels one of two ways: “Surprise me!” This is the attitude you must adopt when you first get a dataset. You are just happy to import without an error. You start to explore. You discover flaws in the data and/or the import. You address them. Lather, rinse, repeat. “Another day in paradise.” This is the attitude when you bring in a tidy dataset you have maniacally cleaned in one or more cleaning scripts. There should be no surprises. You should express your expectations about the data in formal assertions at the very start of these downstream scripts. In the second case, and as the first cases progresses, you actually know a lot about how the data is/should be. My main import advice: use the arguments of your import function to get as far as you can, as fast as possible. Novice code often has a great deal of unnecessary post import fussing around. Read the docs for the import functions and take maximum advantage of the arguments to control the import. 9.1.2 Data export mindset There will be many occasions when you need to write data from R. Two main examples: a tidy ready-to-analyze dataset that you heroically created from messy data a numerical result from data aggregation or modelling or statistical inference First tip: today’s outputs are tomorrow’s inputs. Think back on all the pain you have suffered importing data and don’t inflict such pain on yourself! Second tip: don’t be too cute or clever. A plain text file that is readable by a human being in a text editor should be your default until you have actual proof that this will not work. Reading and writing to exotic or proprietary formats will be the first thing to break in the future or on a different computer. It also creates barriers for anyone who has a different toolkit than you do. Be software-agnostic. Aim for future-proof and moron-proof. How does this fit with our emphasis on dynamic reporting via R Markdown? There is a time and place for everything. There are projects and documents where the scope and personnel will allow you to geek out with knitr and R Markdown. But there are lots of good reasons why (parts of) an analysis should not (only) be embedded in a dynamic report. Maybe you are just doing data cleaning to produce a valid input dataset. Maybe you are making a small but crucial contribution to a giant multi-author paper. Etc. Also remember there are other tools and workflows for making something reproducible. I’m looking at you, make. 9.2 Load the tidyverse The main package we will be using is readr, which provides drop-in substitute functions for read.table() and friends. However, to make some points about data export and import, it is nice to reorder factor levels. For that, we will use the forcats package, which is also included in the tidyverse meta-package. library(tidyverse) #&gt; ── Attaching packages ──── tidyverse 1.3.0 ── #&gt; ✓ ggplot2 3.3.2 ✓ purrr 0.3.4 #&gt; ✓ tibble 3.0.3 ✓ dplyr 1.0.2 #&gt; ✓ tidyr 1.1.2 ✓ stringr 1.4.0 #&gt; ✓ readr 1.3.1 ✓ forcats 0.5.0 #&gt; ── Conflicts ─────── tidyverse_conflicts() ── #&gt; x dplyr::filter() masks stats::filter() #&gt; x dplyr::lag() masks stats::lag() 9.3 Locate the Gapminder data We could load the data from the package as usual, but instead we will load it from tab delimited file. The gapminder package includes the data normally found in the gapminder data frame as a .tsv. So let’s get the path to that file on your system using the fs package. library(fs) (gap_tsv &lt;- path_package(&quot;gapminder&quot;, &quot;extdata&quot;, &quot;gapminder.tsv&quot;)) #&gt; /Users/hgstp/Library/R/4.0/library/gapminder/extdata/gapminder.tsv 9.4 Bring rectangular data in The workhorse data import function of readr is read_delim(). Here we’ll use a variant, read_tsv(), that anticipates tab-delimited data: gapminder &lt;- read_tsv(gap_tsv) #&gt; Parsed with column specification: #&gt; cols( #&gt; country = col_character(), #&gt; continent = col_character(), #&gt; year = col_double(), #&gt; lifeExp = col_double(), #&gt; pop = col_double(), #&gt; gdpPercap = col_double() #&gt; ) str(gapminder, give.attr = FALSE) #&gt; tibble [1,704 × 6] (S3: spec_tbl_df/tbl_df/tbl/data.frame) #&gt; $ country : chr [1:1704] &quot;Afghanistan&quot; &quot;Afghanistan&quot; &quot;Afghanistan&quot; &quot;Afghani&quot;.. #&gt; $ continent: chr [1:1704] &quot;Asia&quot; &quot;Asia&quot; &quot;Asia&quot; &quot;Asia&quot; ... #&gt; $ year : num [1:1704] 1952 1957 1962 1967 1972 ... #&gt; $ lifeExp : num [1:1704] 28.8 30.3 32 34 36.1 ... #&gt; $ pop : num [1:1704] 8425333 9240934 10267083 11537966 13079460 ... #&gt; $ gdpPercap: num [1:1704] 779 821 853 836 740 ... For full flexibility re: specifying the delimiter, you can always use readr::read_delim(). There’s a similar convenience wrapper for comma-separated values: read_csv(). The most noticeable difference between the readr functions and base is that readr does NOT convert strings to factors by default. In the grand scheme of things, this is better default behavior, although we go ahead and convert them to factor here. Do not be deceived – in general, you will do less post-import fussing if you use readr. gapminder &lt;- gapminder %&gt;% mutate(country = factor(country), continent = factor(continent)) str(gapminder) #&gt; tibble [1,704 × 6] (S3: spec_tbl_df/tbl_df/tbl/data.frame) #&gt; $ country : Factor w/ 142 levels &quot;Afghanistan&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... #&gt; $ continent: Factor w/ 5 levels &quot;Africa&quot;,&quot;Americas&quot;,..: 3 3 3 3 3 3 3 3 3 3 ... #&gt; $ year : num [1:1704] 1952 1957 1962 1967 1972 ... #&gt; $ lifeExp : num [1:1704] 28.8 30.3 32 34 36.1 ... #&gt; $ pop : num [1:1704] 8425333 9240934 10267083 11537966 13079460 ... #&gt; $ gdpPercap: num [1:1704] 779 821 853 836 740 ... #&gt; - attr(*, &quot;spec&quot;)= #&gt; .. cols( #&gt; .. country = col_character(), #&gt; .. continent = col_character(), #&gt; .. year = col_double(), #&gt; .. lifeExp = col_double(), #&gt; .. pop = col_double(), #&gt; .. gdpPercap = col_double() #&gt; .. ) 9.4.1 Bring rectangular data in – summary Default to readr::read_delim() and friends. Use the arguments! The Gapminder data is too clean and simple to show off the great features of readr, so I encourage you to check out the part of the introduction vignette on column types. There are many variable types that you will be able to parse correctly upon import, thereby eliminating a great deal of post-import fussing. 9.5 Compute something worthy of export We need compute something worth writing to file. Let’s create a country-level summary of maximum life expectancy. gap_life_exp &lt;- gapminder %&gt;% group_by(country, continent) %&gt;% summarise(life_exp = max(lifeExp)) %&gt;% ungroup() #&gt; `summarise()` regrouping output by &#39;country&#39; (override with `.groups` argument) gap_life_exp #&gt; # A tibble: 142 x 3 #&gt; country continent life_exp #&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; #&gt; 1 Afghanistan Asia 43.8 #&gt; 2 Albania Europe 76.4 #&gt; 3 Algeria Africa 72.3 #&gt; 4 Angola Africa 42.7 #&gt; 5 Argentina Americas 75.3 #&gt; 6 Australia Oceania 81.2 #&gt; 7 Austria Europe 79.8 #&gt; 8 Bahrain Asia 75.6 #&gt; 9 Bangladesh Asia 64.1 #&gt; 10 Belgium Europe 79.4 #&gt; # … with 132 more rows The gap_life_exp data frame is an example of an intermediate result that we want to store for the future and for downstream analyses or visualizations. 9.6 Write rectangular data out The workhorse export function for rectangular data in readr is write_delim() and friends. Let’s use write_csv() to get a comma-delimited file. write_csv(gap_life_exp, &quot;gap_life_exp.csv&quot;) Let’s look at the first few lines of gap_life_exp.csv. If you’re following along, you should be able to open this file or, in a shell, use head() on it. country,continent,life_exp Afghanistan,Asia,43.828 Albania,Europe,76.423 Algeria,Africa,72.301 Angola,Africa,42.731 Argentina,Americas,75.32 This is pretty decent looking, though there is no visible alignment or separation into columns. Had we used the base function read.csv(), we would be seeing rownames and lots of quotes, unless we had explicitly shut that down. Nicer default behavior is the main reason we are using readr::write_csv() over write.csv(). It’s not really fair to complain about the lack of visible alignment. Remember we are “writing data for computers”. If you really want to browse around the file, use View() in RStudio or open it in Microsoft Excel (!) but don’t succumb to the temptation to start doing artisanal data manipulations there … get back to R and construct commands that you can re-run the next 15 times you import/clean/aggregate/export the same dataset. Trust me, it will happen. 9.7 Invertibility It turns out these self-imposed rules are often in conflict with one another: Write to plain text files Break analysis into pieces: the output of script i is an input for script i + 1 Be the boss of factors: order the levels in a meaningful, usually non-alphabetical way Avoid duplication of code and data Example: after performing the country-level summarization, we reorder the levels of the country factor, based on life expectancy. This reordering operation is conceptually important and must be embodied in R commands stored in a script. However, as soon as we write gap_life_exp to a plain text file, that meta-information about the countries is lost. Upon re-import with read_delim() and friends, we are back to alphabetically ordered factor levels. Any measure we take to avoid this loss immediately breaks another one of our rules. So what do I do? I must admit I save (and re-load) R-specific binary files. Right after I save the plain text file. Belt and suspenders. I have toyed with the idea of writing import helper functions for a specific project, that would re-order factor levels in principled ways. They could be defined in one file and called from many. This would also have a very natural implementation within a workflow where each analytical project is an R package. But so far it has seemed too much like yak shaving. I’m intrigued by a recent discussion of putting such information in YAML frontmatter (see Martin Fenner blog post, “Using YAML frontmatter with CSV”). 9.8 Reordering the levels of the country factor The topic of factor level reordering is covered in Chapter ??, so let’s Just. Do. It. I reorder the country factor levels according to the life expectancy summary we’ve already computed. head(levels(gap_life_exp$country)) # alphabetical order #&gt; [1] &quot;Afghanistan&quot; &quot;Albania&quot; &quot;Algeria&quot; &quot;Angola&quot; &quot;Argentina&quot; #&gt; [6] &quot;Australia&quot; gap_life_exp &lt;- gap_life_exp %&gt;% mutate(country = fct_reorder(country, life_exp)) head(levels(gap_life_exp$country)) # in increasing order of maximum life expectancy #&gt; [1] &quot;Sierra Leone&quot; &quot;Angola&quot; &quot;Afghanistan&quot; &quot;Liberia&quot; &quot;Rwanda&quot; #&gt; [6] &quot;Mozambique&quot; head(gap_life_exp) #&gt; # A tibble: 6 x 3 #&gt; country continent life_exp #&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; #&gt; 1 Afghanistan Asia 43.8 #&gt; 2 Albania Europe 76.4 #&gt; 3 Algeria Africa 72.3 #&gt; 4 Angola Africa 42.7 #&gt; 5 Argentina Americas 75.3 #&gt; 6 Australia Oceania 81.2 Note that the row order of gap_life_exp has not changed. I could choose to reorder the rows of the data frame if, for example, I was about to prepare a table to present to people. But I’m not, so I won’t. 9.9 saveRDS() and readRDS() If you have a data frame AND you have exerted yourself to rationalize the factor levels, you have my blessing to save it to file in a way that will preserve this hard work upon re-import. Use saveRDS(). saveRDS(gap_life_exp, &quot;gap_life_exp.rds&quot;) saveRDS() serializes an R object to a binary file. It’s not a file you will able to open in an editor, diff nicely with Git(Hub), or share with non-R friends. It’s a special purpose, limited use function that I use in specific situations. The opposite of saveRDS() is readRDS(). You must assign the return value to an object. I highly recommend you assign back to the same name as before. Why confuse yourself?!? rm(gap_life_exp) gap_life_exp #&gt; Error in eval(expr, envir, enclos): object &#39;gap_life_exp&#39; not found gap_life_exp &lt;- readRDS(&quot;gap_life_exp.rds&quot;) gap_life_exp #&gt; # A tibble: 142 x 3 #&gt; country continent life_exp #&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; #&gt; 1 Afghanistan Asia 43.8 #&gt; 2 Albania Europe 76.4 #&gt; 3 Algeria Africa 72.3 #&gt; 4 Angola Africa 42.7 #&gt; 5 Argentina Americas 75.3 #&gt; 6 Australia Oceania 81.2 #&gt; 7 Austria Europe 79.8 #&gt; 8 Bahrain Asia 75.6 #&gt; 9 Bangladesh Asia 64.1 #&gt; 10 Belgium Europe 79.4 #&gt; # … with 132 more rows saveRDS() has more arguments, in particular compress for controlling compression, so read the help for more advanced usage. It is also very handy for saving non-rectangular objects, like a fitted regression model, that took a nontrivial amount of time to compute. You will eventually hear about save() + load() and even save.image(). You may even see them in documentation and tutorials, but don’t be tempted. Just say no. These functions encourage unsafe practices, like storing multiple objects together and even entire workspaces. There are legitimate uses of these functions, but not in your typical data analysis. 9.10 Retaining factor levels upon re-import Concrete demonstration of how non-alphabetical factor level order is lost with write_delim() / read_delim() workflows but maintained with saveRDS() / readRDS(). (country_levels &lt;- tibble(original = head(levels(gap_life_exp$country)))) #&gt; # A tibble: 6 x 1 #&gt; original #&gt; &lt;chr&gt; #&gt; 1 Sierra Leone #&gt; 2 Angola #&gt; 3 Afghanistan #&gt; 4 Liberia #&gt; 5 Rwanda #&gt; 6 Mozambique write_csv(gap_life_exp, &quot;gap_life_exp.csv&quot;) saveRDS(gap_life_exp, &quot;gap_life_exp.rds&quot;) rm(gap_life_exp) head(gap_life_exp) # will cause error! proving gap_life_exp is really gone #&gt; Error in head(gap_life_exp): object &#39;gap_life_exp&#39; not found gap_via_csv &lt;- read_csv(&quot;gap_life_exp.csv&quot;) %&gt;% mutate(country = factor(country)) #&gt; Parsed with column specification: #&gt; cols( #&gt; country = col_character(), #&gt; continent = col_character(), #&gt; life_exp = col_double() #&gt; ) gap_via_rds &lt;- readRDS(&quot;gap_life_exp.rds&quot;) country_levels &lt;- country_levels %&gt;% mutate(via_csv = head(levels(gap_via_csv$country)), via_rds = head(levels(gap_via_rds$country))) country_levels #&gt; # A tibble: 6 x 3 #&gt; original via_csv via_rds #&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 Sierra Leone Afghanistan Sierra Leone #&gt; 2 Angola Albania Angola #&gt; 3 Afghanistan Algeria Afghanistan #&gt; 4 Liberia Angola Liberia #&gt; 5 Rwanda Argentina Rwanda #&gt; 6 Mozambique Australia Mozambique Note how the original, post-reordering country factor levels are restored using the saveRDS() / readRDS() strategy but revert to alphabetical ordering using write_csv() / read_csv(). 9.11 dput() and dget() One last method of saving and restoring data deserves a mention: dput() and dget(). dput() offers this odd combination of features: it creates a plain text representation of an R object which still manages to be quite opaque. If you use the file = argument, dput() can write this representation to file but you won’t be tempted to actually read that thing. dput() creates an R-specific-but-not-binary representation. Let’s try it out. ## first restore gap_life_exp with our desired country factor level order gap_life_exp &lt;- readRDS(&quot;gap_life_exp.rds&quot;) dput(gap_life_exp, &quot;gap_life_exp-dput.txt&quot;) Now let’s look at the first few lines of the file gap_life_exp-dput.txt. structure(list(country = structure(c(3L, 107L, 74L, 2L, 98L, 138L, 128L, 102L, 49L, 125L, 26L, 56L, 96L, 47L, 75L, 85L, 18L, 12L, 37L, 24L, 133L, 13L, 16L, 117L, 84L, 82L, 53L, 9L, 28L, 120L, 22L, 104L, 114L, 109L, 115L, 23L, 73L, 97L, 66L, 71L, 15L, 29L, 20L, 122L, 134L, 40L, 35L, 123L, 38L, 126L, 60L, 25L, 7L, 39L, 59L, 141L, 86L, 140L, 51L, 63L, 64L, 52L, 121L, 135L, 132L, Huh? Don’t worry about it. Remember we are “writing data for computers”. The partner function dget() reads this representation back in. gap_life_exp_dget &lt;- dget(&quot;gap_life_exp-dput.txt&quot;) country_levels &lt;- country_levels %&gt;% mutate(via_dput = head(levels(gap_life_exp_dget$country))) country_levels #&gt; # A tibble: 6 x 4 #&gt; original via_csv via_rds via_dput #&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 Sierra Leone Afghanistan Sierra Leone Sierra Leone #&gt; 2 Angola Albania Angola Angola #&gt; 3 Afghanistan Algeria Afghanistan Afghanistan #&gt; 4 Liberia Angola Liberia Liberia #&gt; 5 Rwanda Argentina Rwanda Rwanda #&gt; 6 Mozambique Australia Mozambique Mozambique Note how the original, post-reordering country factor levels are restored using the dput() / dget() strategy. But why on earth would you ever do this? The main application of this is the creation of highly portable, self-contained minimal examples. For example, if you want to pose a question on a forum or directly to an expert, it might be required or just plain courteous to NOT attach any data files. You will need a monolithic, plain text blob that defines any necessary objects and has the necessary code. dput() can be helpful for producing the piece of code that defines the object. If you dput() without specifying a file, you can copy the return value from Console and paste into a script. Or you can write to file and copy from there or add R commands below. 9.12 Other types of objects to use dput() or saveRDS() on My special dispensation to abandon human-readable, plain text files is even broader than I’ve let on. Above, I give my blessing to store data.frames via dput() and/or saveRDS(), when you’ve done some rational factor level re-ordering. The same advice and mechanics apply a bit more broadly: you’re also allowed to use R-specific file formats to save vital non-rectangular objects, such as a fitted nonlinear mixed effects model or a classification and regression tree. 9.13 Clean up We’ve written several files in this tutorial. Some of them are not of lasting value or have confusing filenames. I choose to delete them, while demonstrating some of the many functions R offers for interacting with the filesystem. It’s up to you whether you want to submit this command or not. file.remove(list.files(pattern = &quot;^gap_life_exp&quot;)) #&gt; [1] TRUE TRUE TRUE 9.14 Pitfalls of delimited files If a delimited file contains fields where a human being has typed, be crazy paranoid because people do really nutty things. Especially people who aren’t in the business of programming and have never had to compute on text. Claim: a person’s regular expression skill is inversely proportional to the skill required to handle the files they create. Implication: if someone has never heard of regular expressions, prepare for lots of pain working with their files. When the header fields (often, but not always, the variable names) or actual data contain the delimiter, it can lead to parsing and import failures. Two popular delimiters are the comma , and the TAB \\t and humans tend to use these when typing. If you can design this problem away during data capture, such as by using a drop down menu on an input form, by all means do so. Sometimes this is impossible or undesirable and you must deal with fairly free form text. That’s a good time to allow/force text to be protected with quotes, because it will make parsing the delimited file go more smoothly. Sometimes, instead of rigid tab-delimiting, whitespace is used as the delimiter. That is, in fact, the default for both read.table() and write.table(). Assuming you will write/read variable names from the first line (a.k.a. the header in write.table() and read.table()), they must be valid R variable names … or they will be coerced into something valid. So, for these two reasons, it is good practice to use “one word” variable names whenever possible. If you need to evoke multiple words, use snake_case or camelCase to cope. Example: the header entry for the field holding the subject’s last name should be last_name or lastName NOT last name. With the readr package, “column names are left as is, not munged into valid R identifiers (i.e. there is no check.names = TRUE)”. So you can get away with whitespace in variable names and yet I recommend that you do not. 9.15 Resources Data import chapter of R for Data Science by Hadley Wickham and Garrett Grolemund (2016). White et al.’s “Nine simple ways to make it easier to (re)use your data” (2013). First appeared in PeerJ Preprints Published in Ideas in Ecology and Evolution in 2013 Section 4 “Use Standard Data Formats” is especially good reading. Wickham’s paper on tidy data in the Journal of Statistical Software (2014). Available as a PDF here Data Manipulation in R by Phil Spector (2008). Available via SpringerLink Author’s webpage GoogleBooks search See Chapter 2 (“Reading and Writing Data”) "],
["references.html", "References", " References "]
]
